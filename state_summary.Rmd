---
author: "Colin Donald"
date: "`r format(Sys.Date(), '%m/%d/%Y')`"
output: 
  word_document: 
    fig_caption: yes
    keep_md: yes
    reference_docx: N:/Status_and_Trend_Reports/Report_Files/Report_Template.docx
    toc: yes
    fig_width: 12
    fig_height: 6
  html_document:
    mode: selfcontained
    number_sections: yes
    template: N:/Status_and_Trend_Reports/Report_Files/report_template.html
    toc: yes
    toc_depth: 5
    toc_float: 
      collapsed: true
      smooth_scroll: true
    fig_width: 12
  pdf_document:
    toc: yes
always_allow_html: yes
params: 
#   basin: "placeholder"
#   param_sum: "placeholder"
#   param_sum_au: "placeholder"
#   owri_summary: "placeholder"
#   owri_version: "placeholder"
#   complete_years: "placeholder"
#   hucs: "placeholder"
#   table_format: "placeholder"
---

```{r setup, include=FALSE}

options(knitr.duplicate.label = 'allow')
options(tinytex.verbose = TRUE)

knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning=FALSE,
                      error = FALSE,
                      cache = FALSE,
                      include = TRUE,
                      fig.keep='all',
                      # fig.path=paste0(out_dir, "/Figures/"),
                      fig.width = 12, 
                      fig.height = 6)

library(dplyr)
library(knitr)
library(kableExtra)
library(captioner)
library(reshape2)
library(leaflet)
library(mapview)
library(readxl)
library(odeqstatusandtrends)
library(odeqassessment)
library(sf)
library(rgdal)
library(ggplot2)
library(tidyverse)
library(lubridate)

# param_sum <- params$param_sum
# param_sum_au <- params$param_sum_au
# basin <- params$basin
# complete_years <- params$complete_years
# hucs <- params$hucs
# table_format <- params$table_format
# name <- "Willamette"
year <- "2020"
start.date = "2000-01-01"
end.date = "2019-12-31"
complete_years <- c(as.integer(substr(start.date, start = 1, stop = 4)):as.integer(substr(end.date, start = 1, stop = 4)))
top_dir <- paste0("N:/Status_and_Trend_Reports/", year,"/")

figs <- captioner::captioner(prefix="Figure")
tbls  <- captioner::captioner(prefix="Table")
eqns <- captioner::captioner(prefix="Equation")

load(file = paste0(top_dir, "Oregon_param_summary_by_station.RData"))
load(file = paste0(top_dir, "Oregon_param_summary_by_AU.RData"))

state_param_sum_stn <- state_param_sum_stn %>% dplyr::filter(!is.na(AU_ID))
state_param_sum_stn <- state_param_sum_stn %>% dplyr::filter(AU_ID != "")
state_param_sum_stn$Char_Name <- odeqstatusandtrends::AWQMS_to_standard(state_param_sum_stn$Char_Name)

state_param_sum_au <- state_param_sum_au %>% dplyr::filter(!is.na(AU_ID))
state_param_sum_au <- state_param_sum_au %>% dplyr::filter(AU_ID != "")
state_param_sum_au$Char_Name <- odeqstatusandtrends::AWQMS_to_standard(state_param_sum_au$Char_Name)

state_param_sum_stn$AU_Type <- dplyr::if_else(grepl("_SR_", state_param_sum_stn$AU_ID),
                                          "Stream",
                                          dplyr::if_else(grepl("_LK_", state_param_sum_stn$AU_ID),
                                                         "Lake",
                                                         dplyr::if_else(grepl("_WS_", state_param_sum_stn$AU_ID),
                                                                        "Watershed Unit",
                                                                        dplyr::if_else(grepl("_EB_", state_param_sum_stn$AU_ID),
                                                                                       "Estuary or Bay",
                                                                                       dplyr::if_else(grepl("_CL_", state_param_sum_stn$AU_ID),
                                                                                                      
                                                                                                      "Coastline",
                                                                                                      NA_character_
                                                                                       )
                                                                        )
                                                         )
                                          )
)
state_param_sum_au$AU_Type <- dplyr::if_else(grepl("_SR_", state_param_sum_au$AU_ID),
                                             "Stream",
                                             dplyr::if_else(grepl("_LK_", state_param_sum_au$AU_ID),
                                                            "Lake",
                                                            dplyr::if_else(grepl("_WS_", state_param_sum_au$AU_ID),
                                                                           "Watershed Unit",
                                                                           dplyr::if_else(grepl("_EB_", state_param_sum_au$AU_ID),
                                                                                          "Estuary or Bay",
                                                                                          dplyr::if_else(grepl("_CL_", state_param_sum_au$AU_ID),
                                                                                                         "Coastline",
                                                                                                         NA_character_
                                                                                          )
                                                                           )
                                                            )
                                             )
)
state_param_sum_stn[state_param_sum_stn$AU_ID == "Sru Lake", "AU_Name"] <- "Sru Lake"
state_param_sum_stn[state_param_sum_stn$AU_ID == "Sru Lake", "AU_Type"] <- "Lake"
state_param_sum_au[state_param_sum_au$AU_ID == "Sru Lake", "AU_Name"] <- "Sru Lake"
state_param_sum_au[state_param_sum_au$AU_ID == "Sru Lake", "AU_Type"] <- "Lake"

status_current <- as.symbol(colnames(state_param_sum_stn)[grep("trend", colnames(state_param_sum_stn)) - 1])

basin_intro <- FALSE

# project_dir <- paste0('N:/Status_and_Trend_Reports/2019/2019-', basin, '/')

# area <- rgdal::readOGR(dsn = gis_dir, layer = 'Report_Units_HUC08', integer64="warn.loss", verbose = FALSE, stringsAsFactors = FALSE)
# area <- area[area$REPORT %in% c(name), ]
# area <- sf::st_as_sf(area)
# area <- sf::st_transform(area, 4326)

# state_wql_streams <- sf::st_read(
#   dsn = "//deqhq1/wqnps/Agriculture/Status_and_Trend_Analysis/R_support_files", 
#   layer = "WQL_Streams_2012",
#   # query = paste0("SELECT * FROM WQL_Streams_2012 WHERE HUC_4TH_CO IN ('",
#   #                paste(raster::unique(param_sum$HUC8), collapse = "', '"), "')"),
#   stringsAsFactors = FALSE, quiet = TRUE
# )
load(file = "//deqhq1/WQNPS/Status_and_Trend_Reports/Lookups_Statewide/huc_crosswalk.RData")
huc_12s <- hucs[hucs$HUC_8 %in% unique(state_param_sum_stn$HUC8),]$HUC_12
state_wql_streams_lines <- sf::st_read(
    dsn = "//deqhq1/GISLIBRARY/Base_Data/DEQ_Data/Water_Quality/WQ_2018_IntegratedReport/WQ_Assessment_2018_20.gdb",
    layer = "Impaired_Pollutant_Rivers_Coast",
    query = paste0("SELECT * FROM Impaired_Pollutant_Rivers_Coast WHERE HUC12 IN ('",
                   paste(huc_12s, collapse = "', '"), "')"),
    stringsAsFactors = FALSE
  )
state_wql_streams_ws <- sf::st_read(
    dsn = "//deqhq1/GISLIBRARY/Base_Data/DEQ_Data/Water_Quality/WQ_2018_IntegratedReport/WQ_Assessment_2018_20.gdb",
    layer = "Impaired_Pollutant_Watershed",
    query = paste0("SELECT * FROM Impaired_Pollutant_Watershed WHERE HUC12 IN ('",
                   paste(huc_12s, collapse = "', '"), "')"),
    stringsAsFactors = FALSE
  )
# state_wql_streams$Char_Name <- unlist(sapply(state_wql_streams$POLLUTANT, AWQMS_Char_Names, USE.NAMES = FALSE))
# state_wql_streams$Char_Name <- odeqstatusandtrends::AWQMS_to_standard(state_wql_streams$Char_Name)
# state_wql_streams <- sf::st_zm(state_wql_streams, what = "ZM")

state_wql_streams_lines$Char_Name <- unlist(sapply(state_wql_streams_lines$Char_Name, AWQMS_Char_Names, USE.NAMES = FALSE))
state_wql_streams_ws$Char_Name <- unlist(sapply(state_wql_streams_ws$Char_Name, AWQMS_Char_Names, USE.NAMES = FALSE))
state_wql_streams_lines$Char_Name <- odeqstatusandtrends::AWQMS_to_standard(state_wql_streams_lines$Char_Name)
state_wql_streams_ws$Char_Name <- odeqstatusandtrends::AWQMS_to_standard(state_wql_streams_ws$Char_Name)
state_wql_streams_lines <- sf::st_zm(state_wql_streams_lines, what = "ZM")
state_wql_streams_ws <- sf::st_zm(state_wql_streams_ws, what = "ZM")

# state_wql_streams <- sf::st_transform(state_wql_streams, 4326)
# state_wql_streams <- dplyr::filter(state_wql_streams[, c("STREAM_NAM", "SEGMENT_ID", "SEASON", "Char_Name", "LISTING_ST", "TMDL_INFO")], Char_Name %in% unique(state_param_sum_stn$Char_Name))
# state_wql_streams_shp <- state_wql_streams %>% dplyr::group_by(Char_Name) %>% dplyr::summarise(geometry = sf::st_union(geometry))

state_wql_streams_lines <- sf::st_transform(state_wql_streams_lines, 4326)
state_wql_streams_lines <- dplyr::filter(state_wql_streams_lines[, c("AU_Name", "AU_ID", "Period", "Char_Name", "IR_category")],
                               Char_Name %in% unique(state_param_sum_stn$Char_Name))

state_wql_streams_ws <- sf::st_transform(state_wql_streams_ws, 4326)
state_wql_streams_ws <- dplyr::filter(state_wql_streams_ws[, c("AU_Name", "AU_ID", "Period", "Char_Name", "IR_category")],
                                      Char_Name %in% unique(state_param_sum_stn$Char_Name))

# state_wql_streams_lines_shp <- state_wql_streams_lines %>% dplyr::group_by(Char_Name) %>% dplyr::summarise(Shape = sf::st_union(Shape))
# state_wql_streams_ws_shp <- state_wql_streams_ws %>% dplyr::group_by(Char_Name) %>% dplyr::summarise(Shape = sf::st_union(Shape))

# wql_streams <- wql_streams[lapply(wql_streams$`_ogr_geometry_`, length) != 0,]

if(!dir.exists(paste0(top_dir, "Statewide Maps"))) {dir.create(paste0(top_dir, "Statewide Maps"))}

state_map_dir <- paste0(top_dir, "Statewide Maps/")

lgnd <- base64enc::base64encode("//deqhq1/WQNPS/Status_and_Trend_Reports/Figures/map_overview_legend.png")

table_style <- function(x){
  kableExtra::kable_styling(x, latex_options = "repeat_header", repeat_header_continued = T,
                            bootstrap_options = c("striped", "hover", "condensed", "responsive"))
}

```

---
title: "`r paste(year, 'Oregon Statewide Status and Trends Report')`"
---

# Introduction

This report presents the results of a statewide water quality status and trends analysis as well as a summary of best management practices implemented. The analysis is intended to answer these four questions:

*	What is the status of water quality in Oregon? Are waterbodies attaining water quality standards for bacteria, dissolved oxygen, pH, and temperature? 
*	Where applicable, are Total Maximum Daily Load (TMDL) targets established for total phosphorus, total suspended solids, or temperature being attained? 
*	What are the trends in water quality?
* What watershed restoration or protection actions have been implemented?

DEQ conducted this analysis by assembling surface water quality data and information about best management practices implemented from readily accessible public databases, comparing these water quality data to the appropriate Oregon water quality standards or TMDL targets, and determining the status and trends where data and information of sufficient quality and quantity are available. Results are summarized for each of the 19 administrative basins in Oregon as well as the Columbia and Snake Rivers.

A webmap tool is also available on DEQ’s website to search for and review results. The current URL for this website is https://www.oregon.gov/deq/wq/programs/Pages/wqstatustrends.aspx.

The results of this analysis inform DEQ, other state and federal agencies, and the public on the condition of waters and if TMDLs are being achieved; if water quality is improving or degrading; the pace of improvement or degradation; what actions, if any, are being taken to improve water quality, and where water quality data are and are not being collected.

# Analysis Area and Tribal Waters

Only those waters that are under the State of Oregon’s jurisdiction are evaluated in this report. The State of Oregon communicates with Oregon's nine federally-recognized Tribes in a government-to-government relationship to develop and implement agency programs that may affect the Tribes. Oregon DEQ does not assume jurisdiction to designate beneficial uses, apply water quality standards, list impaired waters, or develop TMDLs within tribal territory, except by cooperative agreement with tribal governments. In 2017, DEQ conducted a water quality standards georeferencing project to map the extent of designated beneficial uses, water quality standards, and assessment units for reporting of the Clean Water Act Section 303(d) impaired waters list. As part of this effort, DEQ collected the best available information on the location of Tribal Reservation and Off-Reservation Trust Lands. DEQ only assessed waterbodies and data collected outside of Tribal Reservation or Off-Reservation Trust Land boundaries in the status and trends analysis.

# Methods

## Data Sources

Water quality data were retrieved from DEQ's [Ambient Water Quality Monitoring System (AWQMS)][3.1.1], which integrates DEQ water quality data with other publicly available data sources (including the now retired DEQ LASAR database); the [Water Quality Portal][3.1.2], which includes data from the U.S. Environmental Protection Agency ([WQX/STORET][3.1.3]) database, USGS's National Water Information System ([NWIS][3.1.4]), and other federal agencies, Tribes, and various third parties; NOAA’s [National Estuarine Research Reserve System][3.1.5]; [EIM][3.1.6] (Washington Department of Ecology database); and data obtained during DEQ’s Integrated Report “call for data” process. 

Information about watershed improvement projects and the associated on the ground treatments that were implemented were obtained from the [Oregon Watershed Restoration Inventory][3.1.7] (OWRI) database maintained by the Oregon Watershed Enhancement Board (OWEB).

[3.1.1]: https://www.oregon.gov/deq/wq/pages/wqdata.aspx
[3.1.2]: https://www.waterqualitydata.us
[3.1.3]: https://www.epa.gov/waterdata/water-quality-data-wqx
[3.1.4]: https://waterdata.usgs.gov/nwis
[3.1.5]: https://coast.noaa.gov/nerrs
[3.1.6]: https://ecology.wa.gov/Research-Data/Data-resources/Environmental-Information-Management-database
[3.1.7]: https://www.oregon.gov/oweb/data-reporting/Pages/owri.aspx

## QA/QC Requirements

All data used in the Status and Trends Report must have a project plan (Quality Assurance Project Plan (QAPP) or similar) or use widely accepted sampling and analysis methods. Internal DEQ data and data collected through the Volunteer Monitoring Program must have a Data Quality Level (DQL) of A or B. Data quality levels for parameters measured in the field are assigned following [DEQ’s Data Quality Matrix][3.2.1] (DEQ, 2013). The data quality matrix defines the accuracy and precision criteria for field audits and calibration verifications respectively. Analytical or laboratory analyzed data are assigned data quality levels based on quality control and assurance protocols and internal data review. Data submitted through the Integrated Report call for data or originally obtained from the Water Quality Portal were included if they had a result status of “Final”, “Accepted”, or “Validated”. We relied on the quality control checks implemented by OWEB for treatment data obtained from OWRI.

Monitoring data typically includes results that are reported as "non-detects". Non-detects or censored data are reported when very small concentrations cannot be precisely measured due to limitations in field and laboratory analysis procedures. All that is known is the true result falls somewhere between zero and the reporting limit. Each analytical procedure has a Method Detection Level (MDL) and a Minimum Reporting Level (MRL). The MDL is the concentration at which a sample can be discerned from a sample blank. The MRL is the lowest concentration where an analyte can be both detected and an accurate concentration quantified. We use the generic term "Quantitation Limit" (QL) to include MRL, MDL and any other reporting limits used by third parties. For this analysis, we interpreted non-detect results using the approach described in DEQ's white paper on censored data (DEQ, 2018). The approach is summarized as follows:

* When the QL was greater than the numeric criteria value or TMDL target, ½ of the value of the water quality criteria was substituted for any result reported as censored.

* When the QL was less than the numeric criteria or TMDL target, or there was no TMDL target, ½ of the value of the lowest QL was substituted for any result reported as censored.

* When results were reported as greater than the maximum QL, the QL value was used.

Additional QA/QC checks included reviewing for missing sample timestamp and inconsistencies with the station description and station location (latitude and longitude). Any station inconsistencies were corrected. If the sampling location could not be determined, or had no assigned assessment unit or reach code, data at that station were not used. Multiple stations that appear to have the same data were also reviewed and corrected. This can occur when the data is in two different databases with different station IDs assigned. We also made sure all results had a datetime. 

For samples that were taken for the purpose of auditing the field data (often called replicates or duplicates) the field samples were prioritized and the replicates removed if the DQL for both the field sample and duplicate were the same. If the DQLs were different, the sample with the higher DQL was used. For samples that appear to be replicates or samples made at various depths (i.e. the sample date/time, sample location, and sample parameter were the same) but were not labeled as replicates or depth samples, we took the mean of the samples. The samples missing sampling dates were not used. Results in units of ug/L were converted to mg/L and temperature data measured in degrees Fahrenheit were converted to degrees Celsius.

Results were dropped and not used in this analysis when one or more QA/QC requirements were not met or when other issues identified during the QA/QC process could not be resolved. A summary of stations with dropped data are provided in the Appendices. If the data were dropped because of low data quality level grades or missing timestamps the number of dropped results were summarized in addition to the date range when the data were dropped.

[3.2.1]: http://www.oregon.gov/deq/FilterDocs/DataQualMatrix.pdf

## Period of Analysis

Water quality data collected over a twenty-year period starting `r format(lubridate::ymd(start.date), format="%B %d, %Y")` and ending on `r format(lubridate::ymd(end.date), format="%B %d, %Y")` were retrieved from the data sources identified in Section 3.1.

For assessment of status, DEQ divided the twenty-year period of analysis into five shorter periods with each shorter period spanning four years. Only data collected within the four-year period were used to determine status for that period. DEQ defined the five status periods by the following calendar years:

*	`r paste(complete_years[1], "–", complete_years[4])`
*	`r paste(complete_years[5], "–", complete_years[8])`
*	`r paste(complete_years[9], "–", complete_years[12])`
*	`r paste(complete_years[13], "–", complete_years[16])`
*	`r paste(complete_years[17], "–", complete_years[20])`

Trends were evaluated over the entire twenty-year period. Minimum data requirements to assess trend are discussed in Section 3.5.

## Water Quality Status Assessment

The status assessment is an evaluation of water quality data to determine if a waterbody attains water quality standards or TMDL targets. An attainment assessment was made for bacteria (*E. coli*, *Enterococcus*, and Fecal Coliform), dissolved oxygen, pH, and temperature in relation to the applicable numeric water quality criterion. For some waterbodies the applicable water quality criterion for these parameters is a narrative non-numeric criterion. In this situation, status was not determined. We used the 2018/2020 Integrated Report assessment methodology (DEQ, 2020) to determine attainment within each status period. The methodology considers all the applicable criteria for each parameter as well as the number of excursions for attainment conclusions. The specific methodology for each status category are described for each parameter in the sections below.

Oregon does not have statewide numeric water quality standards for total phosphorus (TP) or total suspended solids (TSS); however, sometimes these parameters are identified as pollutants that contribute to non-attainment of other water quality standards. Often the impairment is based on standards established for dissolved oxygen, pH, or sediment. An attainment assessment was made for total phosphorus (TP) or total suspended solids (TSS) where a TMDL target has been established for these parameters.

### Assessment Units

Water quality status was assessed at both monitoring stations and waterbody-based assessment units (AUs). The AUs incorporate the High Resolution National Hydrography (NHDH) framework with environmentally and hydrologically relevant breaks of water bodies, and remain the same over time (fixed units). The NHDH is a digital geospatial dataset that represents the surface water of the entire United States at a scale of 1:24,000 resolution or better. It is now the national and state hydrologic framework standard, replacing the LLID system. The AUs in this report consist of “Stream”, “Watershed Unit”, “Lake”, “Estuary or Bay”, and “Coastline”. Stream assessment units are defined for the streams with a Strahler Stream Order (Strahler, 1952; Horten, 1945) of five and higher and are grouped based on designated use, stream order change, or a break at a HUC 10 or watershed boundary. All streams with a Strahler Stream Order of four or less are grouped into a watershed unit that is broken at the HUC 12 or smaller sub-watershed boundary. Lakes and reservoirs greater than 20 hectares are classified as lake assessment units. DEQ uses the Coastal and Marine Ecological Classification Standard (FGDC, 2012) to define the extent of estuaries or bays, as well as coastline assessment units.

### Status Reporting and Definitions

The status assessment results are reported and presented in a number of ways. For each station or AU we report the status result in the following way:

* __Attaining__: When results demonstrate attainment of the water quality criteria or TMDL targets in a 4-year status period.

* __Not Attaining__: When results do not attain the water quality criteria or TMDL targets in a 4-year status period.

* __Unassessed__: When there are no results available or when there are results but no numeric water quality criteria or TMDL targets to evaluate attainment against during a 4-year status period. The later condition occurs where there are total phosphorus or total suspended solids data available in an area but no TMDL targets established in that area.

We define “results” as a water quality observation or a calculated summary in the statistical units of the water quality criteria (i.e. geomean or 7-day average daily maximum). An “excursion” occurs when a result is worse than the water quality standard or TMDL target. Having one or more excursions does not always result in a non attaining status. The critical number of excursions for a non attaining status is defined by each parameters assessment protocol.

For each parameter and within each status period, we calculate and report on the total number of results, total excursions, and the minimum, maximum, and median excursion result values. For stations that have total phosphorus or total suspended solids status of 'Unassessed' due to there being no TMDL targets, the minimum, median, and maximum values for all results are provided. Results are also plotted as a timeseries with the applicable water quality standard or TMDL target included on the plot. Excursions are noted. The timeseries plots are displayed in the Water Quality Status and Trend web-based results mapper found at the following URL https://www.oregon.gov/deq/wq/programs/Pages/wqstatustrends.aspx.

### Exact Binomial Test

An exact binomial test was used to determine the critical number of excursions required to differentiate between a non-attaining and attaining status for bacteria (*E. coli* freshwater contact recreation), instantaneous dissolved oxygen, and the pH criteria. The critical number of excursions is determined using the inverse cumulative density function of a binomial distribution as implemented in R (R Core Team, 2020) given a 90% probability, the number results within the status period, and a 10% excursion rate. When the total number of results was less than or equal to 11, only two or more excursions were required for non attainment. This approach is consistent with the methods used for the 2018/2020 305(b)/303(d) Integrated Report (DEQ, 2020).

### Bacteria

#### Bacteria Criteria

Results for bacteria samples were compared to the applicable bacteria criterion as found in [OAR 340-041-0009][3.4.3]. 

**OAR 340-041-0009**  
**Bacteria**

(1)	Numeric Criteria: Organisms commonly associated with fecal sources may not exceed the criteria in subsections (a)-(c) of this section:

|   (a)	Freshwater contact recreation:  
|     (A)	A 90-day geometric mean of 126 *E. coli* organisms per 100 mL;  
|     (B)	No single sample may exceed 406 *E. coli* organisms per 100 mL.

|   (b)	Coastal water contact recreation, as designated in OAR 340-041-0101, 340-041-220, 340-041-230, 340-041-300 and 340-041-0320:  
|     (A)	A 90-day geometric mean of 35 enterococcus organisms per 100 mL;  
|     (B)	Not more than ten percent of the samples may exceed 130 organisms per 100 mL.

|   (c)	Shellfish harvesting, as designated in 340-041-0101, 340-041-220, 340-041-230, 340-041-300 and 340-041-0320:  
|     (A)	A fecal coliform median concentration of 14 organisms per 100 mL;  
|     (B)	Not more than ten percent of the samples may exceed 43 organisms per 100 mL.

(2)	A minimum of five samples in a 90-day period is required for calculating the criteria in sections (1)(a)(A) and (1)(b)(A) and (B) of this rule.

(3)	Raw Sewage Prohibition: No sewage may be discharged into or in any other manner be allowed to enter the waters of the State, unless such sewage has been treated in a manner the Department approved or otherwise allowed by these rules.

(4)	Animal Waste: Runoff contaminated with domesticated animal wastes must be minimized and treated to the maximum extent practicable before it is allowed to enter waters of the State.

(5)	Bacterial pollution or other conditions deleterious to waters used for domestic purposes, livestock watering, irrigation, bathing, or shellfish propagation, or otherwise injurious to public health may not be allowed.

[3.4.3]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68695

#### Bacteria Assessment Protocol

Bacteria related to fecal sources can impair beneficial uses of water for recreation and fishing, specially, shellfish harvesting. Oregon has established water quality standards for relevant bacterial indicators for specific designated uses and various water types (`r tbls(name = "bacteriaIndicators", display="cite")`).

The indicators are:

* *E. coli* for contact recreation in freshwater lakes, rivers, and streams;
* *Enterococcus* for contact recreation in coastal marine and estuary waters; and
* Fecal coliform for shellfish harvesting in marine and estuarine waters.

As salinity increases in estuarine waters, *E. coli* tend to die-off while *Enterococci* remain viable. When data and information for the applicable bacterial indicator in a marine, estuarine, or freshwater location are available, the corresponding criteria are applied to assess each use designated for the water.

```{r tbl-bacteria-indicators}

bacteria.indicators.tbl <- data.frame(du=c("Freshwater contact recreation","Coastal water contact recreation","Shellfish harvesting"),
                                      indicator=c("*E. coli*","*Enterococcus*","Fecal coliform"),
                                      critera=c("Geometric mean <= 126","Geometric mean <= 35", "Median <= 14"),
                                      thresh=c("No more than 10% > 406","No more than 10% > 130", "No more than 10% > 43"))

colnames(bacteria.indicators.tbl) <- c("Designated use", 
                                       "Bacterial indicator",
                                       "Criteria metric (CFU / 100 mL)", 
                                       "Threshold Value (CFU / 100 mL)")

knitr::kable(bacteria.indicators.tbl, 
             padding = 0, digits = 1, format = "pandoc",
             row.names = FALSE,
             caption = tbls(name = "bacteriaIndicators", 
                            caption = "Bacterial Indicators and Criteria."))

```

A geometric mean is calculated on a rolling basis for each 90-day period of data available at a sampling location. A minimum of five samples collected on different days is required to calculate a 90-day rolling geometric mean. The 90-day geometric mean ($GM90$) of bacteria concentration is calculated using `r eqns(name = "eqns-GM90", display="cite")` by taking the nth root of the product of the concentration of each sample collected within a 90-day period for which $n$ ≥ 5.

`r eqns(name = "eqns-GM90", caption = "Geometric Mean Equation.")`

$$GM90 = \sqrt[n]{x_{1}x_{2}...x_{n}}$$  

Where:  
$GM90$ = The geometric mean over a 90-day period.  
$n$ = number of samples.  
$x_n$ = bacteria sample concentration, as number of organisms per 100 mL.

The median sample concentration is calculated for the entire analysis period once there are at least five samples available.

####	Bacteria Status Definitions

Bacteria status assessment results are reported and presented in the following way:

#####	Freshwater contact recreation

* __Attaining__: When there are no excursions of the 126 *E. coli* organisms per 100 mL geomean criterion, **AND** when there are five or more samples and the number of excursions of the 406 *E. coli* organisms per 100 mL criterion within any 90-day period is no more than 10% of all samples according to the exact binomial test.

*	__Not Attaining__: When there is at least one excursion of the 126 *E. coli* organisms per 100 mL geomean criterion, **OR** when there are five or more samples and the number of excursions of the 406 *E. coli* organisms per 100 mL criterion within any 90-day period are greater than 10% of all samples according to the exact binomial test.

*	__Unassessed__: When there are less than five samples within any 90-day period available. Under these circumstances, the reasons for unassessed status are reported as “No Results” for insufficient samples.

#####	Coastal water contact recreation

* __Attaining__: When there are five or more 90-day geometric mean results and all are less than or equal to 35 *Enterococci* organisms per 100 mL, **AND** when there are 10 or more samples and the number of excursions of the 130 *Enterococci* organisms per 100 mL criterion is no more than 10% of samples within a 90-day period. When there are only five to nine samples available, no more than one excursion of the 130 *Enterococci* organisms per 100 mL criterion.

*	__Not Attaining__: When there are five or more a 90-day geometric mean results available and there is any excursion of the 35 *Enterococci* organisms per 100 mL criterion; **OR** when there are 10 or more samples and the number of excursions of the 130 *Enterococci* organisms per 100 mL criterion is greater than 10% of all samples within any 90-day period. When there are only five to nine samples available for a given 90-day period and there are two or more excursions of the 130 *Enterococci* organisms per 100 mL criterion.

*	__Unassessed__: When a geometric mean cannot be calculated because there are less than five samples within any 90-day period available. Under these circumstances, the reasons for unassessed status are reported as “No Results” for insufficient number of samples.

#####	Shellfish harvesting

* __Attaining__: When there are five or more fecal coliform samples and the median concentration is less than or equal to 14 fecal coliform organisms per 100 mL; **AND** when there are 10 or more samples and the number of excursions of the 43 fecal coliform organisms per 100 mL criterion is no more than 10% of all samples. If there are only five to nine samples available, no more than one excursion of the 43 fecal coliform organisms per 100 mL criterion.

*	__Not Attaining__: When there are five or more fecal coliform samples and the median concentration greater than 14 fecal coliform organisms per 100 mL, **OR** when there are 10 or more samples and the number of excursions of the 43 fecal coliform organisms per 100 mL criterion is greater than 10% of all samples. When there are only five to nine samples available and two or more of the samples are greater than the 43 fecal coliform organisms per 100 mL criterion.

*	__Unassessed__: When there are less than five samples within any 90-day period. Under these circumstances, the reasons for unassessed status are reported as “No Results” for insufficient samples.

### Dissolved Oxygen

#### Dissolved Oxygen Criteria

Dissolved oxygen status was assessed by comparing the observed concentration values to the applicable water quality criterion found in [OAR 340-041-0016][3.4.4].

**OAR 340-041-0016**  
**Dissolved Oxygen**

Dissolved oxygen (DO): No wastes may be discharged and no activities may be conducted that either alone or in combination with other wastes or activities will cause violation of the following standards: The changes adopted by the Commission on January 11, 1996, become effective July 1, 1996. Until that time, the requirements of this rule that were in effect on January 10, 1996, apply:

(1)	For water bodies identified as active spawning areas in the places and times indicated on the following Tables and Figures set out in OAR 340-041-0101 to 340-041-0340: Tables 101B, 121B, and 190B, and Figures 130B, 151B, 160B, 170B, 180A, 201A, 220B, 230B, 260A, 271B, 286B, 300B, 310B, 320B, and 340B, (as well as any active spawning area used by resident trout species), the following criteria apply during the applicable spawning through fry emergence periods set forth in the tables and figures and, where resident trout spawning occurs, during the time trout spawning through fry emergence occurs:

|  (a)	The dissolved oxygen may not be less than 11.0 mg/l. However, if the minimum intergravel dissolved oxygen, measured as a spatial median, is 8.0 mg/l or greater, then the DO criterion is 9.0 mg/l;

|  (b)	Where conditions of barometric pressure, altitude, and temperature preclude attainment of the 11.0 mg/l or 9.0 mg/l criteria, dissolved oxygen levels must not be less than 95 percent of saturation;

|  (c)	The spatial median intergravel dissolved oxygen concentration must not fall below 8.0 mg/l.

(2)	For water bodies identified by the Department as providing cold-water aquatic life, the dissolved oxygen may not be less than 8.0 mg/l as an absolute minimum. Where conditions of barometric pressure, altitude, and temperature preclude attainment of the 8.0 mg/l, dissolved oxygen may not be less than 90 percent of saturation. At the discretion of the Department, when the Department determines that adequate information exists, the dissolved oxygen may not fall below 8.0 mg/l as a 30-day mean minimum, 6.5 mg/l as a seven-day minimum mean, and may not fall below 6.0 mg/l as an absolute minimum;

(3)	For water bodies identified by the Department as providing cool-water aquatic life, the dissolved oxygen may not be less than 6.5 mg/l as an absolute minimum. At the discretion of the Department, when the Department determines that adequate information exists, the dissolved oxygen may not fall below 6.5 mg/l as a 30-day mean minimum, 5.0 mg/l as a seven-day minimum mean, and may not fall below 4.0 mg/l as an absolute minimum;

(4)	For water bodies identified by the Department as providing warm-water aquatic life, the dissolved oxygen may not be less than 5.5 mg/l as an absolute minimum. At the discretion of the Department, when the Department determines that adequate information exists, the dissolved oxygen may not fall below 5.5 mg/l as a 30-day mean minimum, and may not fall below 4.0 mg/l as an absolute minimum;

(5)	For estuarine water, the dissolved oxygen concentrations may not be less than 6.5 mg/l (for coastal water bodies);

(6)	For ocean waters, no measurable reduction in dissolved oxygen concentration may be allowed.

**OAR 340-041-0006**  
**Definitions**

(15) "Daily Mean" for dissolved oxygen means the numeric average of an adequate number of data to describe the variation in dissolved oxygen concentration throughout a day, including daily maximums and minimums. For calculating the mean, concentrations in excess of 100 percent of saturation are valued at the saturation concentration.

(22) “Estuarine Waters” means all mixed fresh and oceanic waters in estuaries or bays from the point of oceanic water intrusion inland to a line connecting the outermost points of the headlands or protective jetties.

(27) "Intergravel Dissolved Oxygen" (IGDO) means the concentration of oxygen measured in the water within the stream bed gravels. Measurements should be taken within a limited time period before emergence of fry.

(34) “Marine Waters” means all oceanic, offshore waters outside of estuaries or bays and within the territorial limits of the State of Oregon.

(38) "Minimum" (Min) for dissolved oxygen means the minimum recorded concentration including seasonal and diurnal minimums.

(39) "Monthly (30-D) Mean Minimum" for dissolved oxygen means the minimum of the 30 consecutive-day floating averages of the calculated daily mean dissolved oxygen concentration.

(59) "Spatial Median" means the value that falls in the middle of a data set of multiple intergravel dissolved oxygen (IGDO) measurements taken within a spawning area. Half the samples should be greater than and half the samples should be less than the spatial median.

(73) "Weekly (7-D) Mean Minimum" for dissolved oxygen means the minimum of the seven consecutive-day floating average of the calculated daily mean dissolved oxygen concentration.

(74) "Weekly (7-Mi) Minimum Mean" for dissolved oxygen means the minimum of the seven consecutive-day floating average of the daily minimum concentration. For application of the criteria, this value is the reference for diurnal minimums.

[3.4.4]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68706

```{r tbl-do-indicators, echo=FALSE, results='asis'}

do.indicators.tbl <- data.frame(du=c("Salmonid Spawning","Cold Water","Cool Water", "Warm Water"),
                                      `30-D`= c("","8.0^2^","6.5","5.5"),
                                      `7-D` = c("11^1^","", "",""),
                                      `7-Mi`= c("","6.5","5.0",""),
                                      `Min` = c("","6.0","4.0","4.0")
)

colnames(do.indicators.tbl) <- c("Use of Protection", 
                                       "30-D",
                                       "7-D", 
                                       "7-Mi",
                                       "Min")

knitr::kable(do.indicators.tbl, 
             format = "pandoc", padding = 2,
             row.names = FALSE,
             caption = tbls(name = "doIndicators", 
                            caption = paste0("Dissolved Oxygen (DO) Concentration Criteria (mg/L).")))
  
```

***Note:***  
30-D: 30-day mean minimum as defined in OAR 340-41-006.  
7-D: 7-day mean minimum as defined in OAR 340-41-006.  
7-Mi: 7-day minimum mean as defined in OAR 340-41-006.  
Min: Absolute minimums for surface samples when applying the averaging period.  
^1^ Where conditions of barometric pressure, altitude, and temperature preclude attainment of the 11.0 mg/L criteria, 95 percent of saturation applies.  
^2^ Where conditions of barometric pressure, altitude, and temperature preclude attainment of the 8.0 mg/L criteria, 90 percent of saturation applies.

#### Dissolved Oxygen Assessment Protocol

Application of the various dissolved oxygen criteria is based on designated fish use as described in OAR 340-041-016 and (`r tbls(name="doIndicators", display="cite")`). The time periods for assessing compliance with the dissolved oxygen standards are defined as the following:

* __Spawning Time-Period__: The spawning criteria shall be applied for places and times indicated, in the tables and figures referenced in OAR-340-041-0016 (1), as having active salmon and steelhead spawning, or any additional assumed spawning by resident trout species. Listed status of waterbodies in violation of the spawning criteria is in effect only during the applicable spawning date range for the waterbody.

* __Year-round__: The year-round dissolved oxygen criteria apply year round. For some locations, a more stringent spawning criteria may apply in addition to the year round criterion for part of the year. Listed status of waterbodies in violation of the year-round criteria are in effect year-round.

If the dissolved oxygen concentration exceeded the water quality criterion, but met the criteria for percent saturation at the same time, it was considered to be attaining the dissolved oxygen criterion. Direct field instrument measurements of percent saturation were used if available. However, if the corresponding percent saturation data was unavailable, and corresponding water temperature data was available, the value was calculated using `r eqns(name = "eqns-DO-Theo", display="cite")` and `r eqns(name = "eqns-DO-PS", display="cite")`. When the dissolved oxygen saturation was measured in excess of 100 percent, the saturation value used was limited to 100 percent for the calculation of metrics.

`r eqns(name = "eqns-DO-Theo",caption = "")`

$$DO_{Theo} = e ^{[-139.34411+\frac{1.575701\times 10^5}{T}-\frac{6.642308\times 10^7}{T^2}+\frac{1.23800\times 10^{10}}{T^3}-\frac{8.621949\times 10^{11}}{T^4}]} \times (1-(0.0001148 \times Site_{elvm}))$$
Where:  
$DO_{Theo}$ = Theoretical Dissolved Oxygen in mg/L.  
$e$ = a constant, the base of the natural logarithm ($\approx 2.71828$).  
$T$ = Temperature in Kelvin.  
$Site_{elvm}$ = Site elevation in meters (recorded field value or derived from a Digital Elevation Model).

`r eqns(name = "eqns-DO-PS",caption = "Percent Dissolved Oxygen Saturation")`

$$ PS = 100\times \frac{DO_{Meas}}{DO_{Theo}} $$
Where:  
$PS$ = Percent saturation dissolved oxygen.  
$DO_{Meas}$ = Measured Dissolved Oxygen in mg/L.  
$DO_{Theo}$ = Theoretical Dissolved Oxygen in mg/L from `r eqns(name = "eqns-DO-Theo", display="cite")`.

The monthly thirty day (30-D) mean minimum, weekly seven-day minimum mean (7-Mi),
and alternate absolute minimum (Min) were only assessed when there were sufficient continuously monitored dissolved oxygen data available.

For calculating daily means and minimums, there needed to be measurements from at least 22 hours in each day. For calculating a 30-day mean minimum, there needed to be at least 29 daily mean values. For calculating a seven-day mean there needed to be at least six daily mean values.

To assess the year-round criteria using continuous data, a minimum of fifteen 30-D results must be available during the year-round critical period (July 1 – September 30) for each status period. To assess the spawning criteria using continuous data, fifteen 7-D results must be availible during the spawning period within each status period.

In the absence of sufficient continuous 30-D or 7-D dissolved oxygen results, attainment of the dissolved oxygen criterion was assessed as instantaneous or “grab” measurements. The daily minimum dissolved oxygen concentration was used as the “grab” sample unit.

Sites having insufficient data to be assessed as continuous data will be assessed according to the instantaneous criteria in the following section. Where multiple samples are collected on the same day, the minimum DO concentration will be used in the assessment.

The Intergravel Dissolved Oxygen criterion (OAR 340-041-0016(1)(a)) was not used in this report because there is no intergravel dissolved oxygen data available.

####	Instantaneous Dissolved Oxygen Status Definitions

Dissolved oxygen status assessment results are reported and presented in the following way when making an assessment against the instantaneous criteria:

*	__Attaining__: When the number of excursions to the applicable instantaneous criterion within a status period is no more than 10% of all samples within a status period in the time-period of interest (spawning or year-round period) according to the exact binomial test **AND** are less than the corresponding percent saturation allowance. 


*	__Not Attaining__: When the number of excursions to the applicable instantaneous criterion within a status period is greater than 10% of all samples within a status period in the time-period of interest (spawning or year-round period) according to the exact binomial test **AND** are less than the percent saturation allowance.

*	__Unassessed__: When there are fewer than five samples available within a status period. Under these circumstances, the reasons for unassessed status are reported as “No Results”.

####	Continuous Dissolved Oxygen Status Definitions

Dissolved oxygen status assessment results are reported and presented in the following way when making an assessment against the continuous criteria:

*	__Attaining__:  When all of the following are true: For the year-round criteria, no more than one excursion of the 30-D criterion **AND** for those waterbodies classified as cold water, the corresponding 30-D metric percent saturation is less than the applicable criterion. No more than one excursion of the applicable 7-Mi criterion. If both the year round (30-D and 7-Mi) are attained, no more than one excursion of the daily minimum criteria. During spawning, no more than one excursion of the 7-D criteria **AND** the corresponding 7-D percent saturation is less than the applicable criterion. If the year round 7-D metric is attained, there can be no more than one excursion of the alternate minimum criteria (Min).

*	__Not Attaining__: When any of the following are true: For the year-round criteria more than one excursion of the 30-D criterion **AND** for those waterbodies classified as cold water, the corresponding 30-D percent saturation is less than the applicable criterion. More than one excursion of the applicable 7-Mi criterion. If both the year round (30-D and 7-Mi) are attained, more than one excursion of the daily minimum (Min) criteria. During spawning, more than one excursion of the 7-D criteria **AND** the corresponding 7-D percent saturation is less than the applicable criterion. If the year round 7-D metric is attained and there is more than one excursion of the alternate minimum criteria (Min).

*	__Unassessed__: When there are fewer than fifteen 30-D results to assess the year-round criteria during the year-round critical period (July 1 – September 30) **OR** fewer than fifteen 7-D results available during the spawning period **OR** when there are insufficient 30-D or 7-D results available and there are less than five daily minimum (Min) results available within a status period. Under these circumstances, the reasons for unassessed status are reported as “No Results”.

### pH

#### pH Criteria

Results for pH from both grab and continuous sample data were compared to the applicable water quality criterion as found in [OAR 340-041-0021][3.4.5].

**OAR 340-041-0021**  
**pH**

(1)	Unless otherwise specified in OAR 340-041-0101 through 340-041-0350, pH values (Hydrogen ion concentrations) may not fall outside the following ranges:  
|  (a)	Marine waters: 7.0-8.5;  
|  (b)	Estuarine and fresh waters: See basin specific criteria (OAR 340-041-0101 through 340-041-0350).

(2)	Waters impounded by dams existing on January 1, 1996, which have pHs that exceed the criteria are not in violation of the standard, if the Department determines that the exceedance would not occur without the impoundment and that all practicable measures have been taken to bring the pH in the impounded waters into compliance with the criteria.

[3.4.5]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68713

**OAR 340-041-0101 through 340-041-0350**  
**Basin-Specific Criteria**

```{r tbl-ph}

tbl.ph<- data.frame(basin=c("replace with pH table"),
                    OAR=c("replace with pH table"),
                    Water=c("replace with pH table"),
                    criteria=c("replace with pH table"))

knitr::kable(tbl.ph, 
             padding = 0, digits = 1, format = "pandoc",
             row.names = FALSE,
             caption = tbls(name = "tbl.ph", 
                            caption = "Summary of pH Basin-Specific Criteria."))

```

####	pH Assessment Protocol

Time Period: pH criteria apply year round as described in `r tbls(name = "tbl.ph", display = "cite")`.

####	pH Status Definitions

pH status assessment results are reported and presented in the following way:

* __Attaining__: When there are five or more samples within a status period, the number of excursions to the minimum or maximum pH criteria is no more than 10% of all the samples within that status period according to the exact binomial test.

*	__Not Attaining__: When there are five or more samples within a status period, the number of excursions to the minimum or maximum pH criteria is greater than 10% of the samples within that status period according to the exact binomial test.

*	__Unassessed__: When there are fewer than five samples within a status period. Under these circumstances, the reasons for unassessed status are reported as “No Results”.

### Temperature

#### Temperature Criteria

Results for continuous temperature data were compared against the applicable temperature criteria found in [OAR 340-041-0028][3.4.6].

[3.4.6]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=244176

**OAR 340-041-0028**  
**Temperature**

[…]

(4)	Biologically Based Numeric Criteria. Unless superseded by the natural conditions criteria described in section (8) of this rule, or by subsequently adopted site-specific criteria approved by EPA, the temperature criteria for State waters supporting salmonid fishes are as follows:

|   (a)	The seven-day-average maximum temperature of a stream identified as having salmon and steelhead spawning use on subbasin maps and tables set out in OAR 340-041-0101 to 340-041-0340: Tables 101B, and 121B, and Figures 130B, 151B, 160B, 170B, 220B, 230B, 271B, 286B, 300B, 310B, 320B, and 340B, may not exceed 13.0 degrees Celsius (55.4 degrees Fahrenheit) at the times indicated on these maps and tables;

|   (b)	The seven-day-average maximum temperature of a stream identified as having core cold water habitat use on subbasin maps set out in OAR 340-041-101 to 340-041-340: Figures 130A, 151A, 160A, 170A, 220A, 230A, 271A, 286A, 300A, 310A, 320A, and 340A, may not exceed 16.0 degrees Celsius (60.8 degrees Fahrenheit);

|   (c)	The seven-day-average maximum temperature of a stream identified as having salmon and trout rearing and migration use on subbasin maps set out at OAR 340-041-0101 to 340-041-0340: Figures 130A, 151A, 160A, 170A, 220A, 230A, 271A, 286A, 300A, 310A, 320A, and 340A, may not exceed 18.0 degrees Celsius (64.4 degrees Fahrenheit);

|   (d)	The seven-day-average maximum temperature of a stream identified as having a migration corridor use on subbasin maps and tables OAR 340-041-0101 to 340-041-0340: Tables 101B, and 121B, and Figures 151A, 170A, and 340A, may not exceed 20.0 degrees Celsius (68.0 degrees Fahrenheit). In addition, these water bodies must have coldwater refugia that are sufficiently distributed so as to allow salmon and steelhead migration without significant adverse effects from higher water temperatures elsewhere in the water body. Finally, the seasonal thermal pattern in Columbia and Snake Rivers must reflect the natural seasonal thermal pattern;

|   (e)	The seven-day-average maximum temperature of a stream identified as having Lahontan cutthroat trout or redband trout use on subbasin maps and tables set out in OAR 340-041-0101 to 340-041-0340: Tables 120B, 140B, 190B, and 250B, and Figures 180A, 201A, and 260A may not exceed 20.0 degrees Celsius (68.0 degrees Fahrenheit);

|   (f)	The seven-day-average maximum temperature of a stream identified as having bull trout spawning and juvenile rearing use on subbasin maps set out at OAR 340-041-0101 to 340-041-0340: Figures 130B, 151B, 160B, 170B, 180A, 201A, 260A, 310B, and 340B, may not exceed 12.0 degrees Celsius (53.6 degrees Fahrenheit). From August 15 through May 15, in bull trout spawning waters below Clear Creek and Mehlhorn reservoirs on Upper Clear Creek (Pine Subbasin), below Laurance Lake on the Middle Fork Hood River, and below Carmen reservoir on the Upper McKenzie River, there may be no more than a 0.3 degrees Celsius (0.5 Fahrenheit) increase between the water temperature immediately upstream of the reservoir and the water temperature immediately downstream of the spillway when the ambient seven-day-average maximum stream temperature is 9.0 degrees Celsius (48 degrees Fahrenheit) or greater, and no more than a 1.0 degree Celsius (1.8 degrees Fahrenheit) increase when the seven-day-average stream temperature is less than 9 degrees Celsius.

[…]

(6)	Natural Lakes. Natural lakes may not be warmed by more than 0.3 degrees Celsius (0.5 degrees Fahrenheit) above the natural condition unless a greater increase would not reasonably be expected to adversely affect fish or other aquatic life. Absent a discharge or human modification that would reasonably be expected to increase temperature, DEQ will presume that the ambient temperature of a natural lake is the same as its natural thermal condition.

(7)	Oceans and Bays. Except for the Columbia River above river mile 7, ocean and bay waters may not be warmed by more than 0.3 degrees Celsius (0.5 degrees Fahrenheit) above the natural condition unless a greater increase would not reasonably be expected to adversely affect fish or other aquatic life. Absent a discharge or human modification that would reasonably be expected to increase temperature, DEQ will presume that the ambient temperature of the ocean or bay is the same as its natural thermal condition.

[…]

(9)	Cool Water Species.

|   (a)	No increase in temperature is allowed that would reasonably be expected to impair cool water species. Waters of the State that support cool water species are identified on subbasin tables and figures set out in OAR 340-041-0101 to 340-041-0340; Tables 140B, 190B and 250B, and Figures 180A, 201A and 340A

|   (b)	See OAR 340-041-0185 for a basin-specific criterion for the Klamath River.

(10) Borax Lake Chub. State waters in the Malheur Lake Basin supporting the Borax Lake chub may not be cooled more than 0.3 degrees Celsius (0.5 degrees Fahrenheit) below the natural condition.

[…]

(12) Implementation of the Temperature Criteria

|   (c)	Air Temperature Exclusion. A water body that only exceeds the criteria set out in this rule when the exceedance is attributed to daily maximum air temperatures that exceed the 90th percentile value of annual maximum seven-day average maximum air temperatures calculated using at least 10 years of air temperature data, will not be listed on the section 303(d) list of impaired waters and sources will not be considered in violation of this rule.

|   (d)	Low Flow Conditions. An exceedance of the biologically-based numeric criteria in section (4) of this rule… will not be considered a permit violation during stream flows that are less than the 7Q10 low flow condition for that water body.

**OAR 340-041-0002**  
**Definitions**

(57) "Seven-Day Average Maximum Temperature" means a calculation of the average of the daily maximum temperatures from seven consecutive days made on a rolling basis.

#### Temperature Assessment Protocol

The applicable temperature criteria in `r tbls(name="tbl.temp.criteria", display="cite")` is based on the seven-day average daily maximum (7DADM) stream temperature metric. When calculating the 7DADM, in order to ensure there were sufficient continuous data to calculate the 7DADM, at least one observation per hour from noon to midnight must have been recorded. In addition, each month could have no more than one day of missing observations to ensure that no more than 10% of the 7DADM results in that month were missing.

The seven-day average daily maximum stream temperature (`r eqns(name="eqns-temp-7DADM", display="cite")`) is an average of the daily maximum water temperatures for seven consecutive days. The average daily maximum temperature value for each seven-day period is assigned to the last (7th) calendar day of each period. The 7DADM is repeated for each consecutive 7-day period on a moving or rolling basis. For example, the 7DADM for August 10 is calculated from the maximum temperature for August 4 to August 10; the 7DADM for August 11 is calculated from August 5 to 11, etc.

`r eqns(name = "eqns-temp-7DADM", caption = "")`

$$7DADM = \frac{1}{7}\sum_{i=1}^7T_{max-i} $$
Where:  
$7DADM$ = the seven-day average daily maximum stream temperature.  
$i$ = day in the sequence.  
$T_{max}$ = maximum temperature of day $i$.

When spawning criteria apply, the first 7-day averaging period begins on the date the spawning period begins. The first 7DADM value will be assigned to the 7th calendar day following the start date of the spawning period. Therefore, the 7th calendar day of the spawning period is the first day that the 7DADM is required to meet the spawning criteria.

```{r tbl-temp}

tbl.temp.criteria <- data.frame(du=c("Salmon & trout rearing & migration", 
                                     "Core cold water habitat",
                                     "Migration corridor (salmon & steelhead)",
                                     "Lahontan cutthroat or redband trout",
                                     "Bull trout spawning & juvenile rearing",
                                     "Salmon & steelhead spawning"),
                                crit=c(18.0, 16.0, 20.0, 20.0, 12.0, 13.0))

colnames(tbl.temp.criteria) <- c("Designated Fish Use", "Temperature Criterion (°C)")

knitr::kable(tbl.temp.criteria, 
             padding = 0, digits = 1, format = "pandoc",
             row.names = FALSE,
             caption = tbls(name = "tbl.temp.criteria", 
                            caption = "Numeric Temperature Criteria."))


```


##### Designated Fish Uses

The year-round fish uses designated for protection of fish and aquatic life are indicated in in OAR 340-041-0101 to 340-041-0340: Figures 130A, 151A, 160A, 170A, 180A, 201A, 220A, 230A, 260A, 271A, 286A, 300A, 310A, 320A, and 340A; Tables 101B, 120B, 121B, 130B 140B,151B, 160B, 170B, 180A, 190B, 201A, 250B, 260A, 310B, and 340B. For convenience, the information from the fish use figures and tables are also reproduced on the DEQ water quality standards maps web tool (under development).

##### Designated Spawning Time Periods

In streams designated as salmon and steelhead spawning areas, the salmon & steelhead spawning criterion (13°C) were assessed only during the time periods indicated in tables and figures referenced in OAR 340-041-0101 to 340-041-0340: Tables 101B, and 121B, and Figures 130B, 151B, 160B, 170B, 220B, 230B, 271B, 286B, 300B, 310B, 320B, and 340B. Outside of these designated spawning time periods, the year-round criteria were assessed. 

##### Application of the Cool Water Species Narrative Criterion for Temperature in OAR 340-041-0028 (9)(a). 

The Upper Klamath and Lost Subbasins temperature TMDL (DEQ, 2019b) established a numeric benchmark implementing the cool water species narrative as an instream daily maximum temperature target of 28°C. In the Lost River, Lost River Diversion Channel, and Klamath Straits Drain, the instream daily maximum temperature target is 27.9°C to account for the 0.1°C set aside in the TMDL for reserve capacity. In other subbasins where the cool water species narrative criterion applies, there was no assessment of the cool water species criterion.

##### Applicability

For tributary waters that are not identified on the “Fish Use Designations” maps referenced in section (4) of the rule, the applicable criteria for these waters are the same criteria as is applicable to the nearest downstream water body depicted on the applicable map. This does not apply to the “Salmon and Steelhead Spawning Use Designations” maps.

####	Temperature Status Definitions

Temperature status assessment results are reported and presented in the following way:

*	__Attaining__: When there is one or less excursion of the applicable numeric temperature criteria within a three-year period **OR** no excursions of the cool water species Upper Klamath and Lost Subbasins temperature TMDL target during a status period.

*	__Not Attaining__: When there are two or more excursions of the applicable numeric criteria within a three-year period **OR** one or more excursions to the cool water species Upper Klamath and Lost Subbasins temperature TMDL target during a status period.

*	__Unassessed__: When there are no results available or when there are results but no numeric water quality criteria to evaluate attainment against. Under these circumstances, the reasons for unassessed status are reported either as “No Results” for no available results or as “No TMDL Target” for a narrative temperature criterion where no TMDL targets have been developed. 

### Total Phosphorus

####	Total Phosphorus Total Maximum Daily Load Targets

```{r tmdl-tp-tss-setup, include=FALSE}
# get data
tmdl_table <- odeqtmdl::tmdl_db %>%
  dplyr::filter(target_type %in% c('concentration', 'temperature') & 
                  mapped & 
                  is.na(target_conditionals_references) &
                  pollutant_name_AWQMS %in% c('Total Phosphorus, mixed forms',
                                              'Total suspended solids')) %>%
  dplyr::select(TMDL_name, TMDL_issue_year, geo_description, pollutant_name_AWQMS, wq_limited_parameters, 
                target_type, target_value, target_units, target_stat_base, season_start,season_end) %>% 
  dplyr::distinct() %>% 
  dplyr::mutate(season_start = format(lubridate::ymd(lubridate::parse_date_time(season_start, orders = "d-m")), format="%b %d"),
                season_end = format(lubridate::ymd(lubridate::parse_date_time(season_end, orders = "d-m")), format="%b %d"),
                period = paste0(season_start," - ",season_end),
                target_value = dplyr::case_when(target_units == 'ug/l' ~ target_value * 0.001,
                                                TRUE ~ target_value),
                target_units = dplyr::case_when(target_units == 'ug/l' ~ 'mg/l',
                                                TRUE ~ target_units),
                target_text=as.character(target_value)) %>%
  dplyr::select(-season_start, -season_end)

# TP TMDL SUMMARY 
tbl.tmdls.tp <- tmdl_table %>%
  dplyr::filter(pollutant_name_AWQMS == "Total Phosphorus, mixed forms") %>% 
  dplyr::select(TMDL_name, TMDL_issue_year, wq_limited_parameters) %>% 
  dplyr::group_by(TMDL_name, TMDL_issue_year) %>% 
  dplyr::summarise(`303(d) Listing Parameter`=paste0(unique(wq_limited_parameters), collapse = ", ")) %>% 
  dplyr::rename(`TMDL Document Name` = TMDL_name,
                `Year TMDL Issued` = TMDL_issue_year)

# TP TABLE FOR EACH TMDL DOC
tmdls.name.tp <- sort(unique(tbl.tmdls.tp$`TMDL Document Name`))
# i <- "Tualatin Subbasin TMDL and WQMP"

```

Oregon does not have explicit water quality standards for total phosphorus (TP); however, TP can be a pollutant that contributes to excursions of water quality standards and impairment of one or more beneficial uses. Often the excursions are for water quality standards established for dissolved oxygen, pH, chlorophyll a, or algae.

In this report, we evaluated status for total phosphorus in waterbodies where a Total Maximum Daily Load (TMDL) has been established and identified total phosphorus as a pollutant with specific concentration targets. `r tbls(name="tbl.tmdls.tp", display="cite")` summarizes the TMDLs evaluated in this report with TP concentration targets. Table 6 through Table 16 summarizes the specific TP targets in each TMDL including where the target applies, the 303(d) water quality limited parameters, the statistical base for each TMDL target, and the applicable calendar period when the TMDL target applies.

```{r TMDL-TP, echo=FALSE, results='asis'}

if(NROW(tbl.tmdls.tp) > 0){
  print(knitr::kable(tbl.tmdls.tp, format = "pandoc", padding = 2, 
                     caption = tbls(name="tbl.tmdls.tp", 
                                    caption=paste0("Summary of TMDLs with total phosphorus targets that were evaluated in this report."))))
}

for (i in 1:length(tmdls.name.tp)){
  
  tmdls.doc.df_1 <- tmdl_table %>%
    dplyr::filter(pollutant_name_AWQMS == "Total Phosphorus, mixed forms") %>%  
    dplyr::filter(TMDL_name == tmdls.name.tp[i])
  
  year <- unique(tmdls.doc.df_1$TMDL_issue_year)
  
  tmdls.doc.df_2_tp <- tmdls.doc.df_1 %>% 
    dplyr::select(geo_description, wq_limited_parameters, target_text, target_stat_base, period) %>% 
    dplyr::rename(`Geographic Area` = geo_description,
                  `303(d) Listing Parameter` = wq_limited_parameters,
                  `Total Phosphorus Target Concentration mg/L` = target_text,
                  `Statistical Base` = target_stat_base,
                  `Applicable Period` = period)
  
  if(NROW(tmdls.doc.df_2_tp) > 0){
  print(knitr::kable(tmdls.doc.df_2_tp, format = "pandoc", padding = 2, 
                     caption = tbls(name = paste0("tmdls.doc.df_2_tp", tmdls.name.tp[i]),
                                    caption = paste0("Total phosphorus targets in ", tmdls.name.tp[i], " (DEQ, ", year, ")."))))
  }
}

```

The total phosphorus targets that were established for the Clear Lake Watershed and the Yamhill River Subbasin were adopted into the Oregon Administrative Rules ([OAR 340-041-0225][3.4.8.1] and [OAR 340-041-0345][3.4.8.2]).

**OAR 340-041-0225**  
**Basin-Specific Criteria (Mid Coast Basin): Water Quality Standards and Policies for this Basin**

[...]

(3)	Nutrients in Clear Lake Watershed. In order to preserve the existing high quality water in Clear Lake north of Florence for use as a public water supply source requiring only minimal filtration, it is the policy of the Environmental Quality Commission to protect the Clear Lake watershed including both surface and groundwater, from existing and potential contamination sources with the following requirements:

|   (a)	The total phosphorus maximum annual loading discharged into Clear Lake may not exceed 241 pounds per year from all sources.

|   (b)	The total phosphorus maximum annual loading for the Clear Lake watershed may be deemed exceeded if the median concentration of total phosphorus from samples collected in the epilimnion between May 1 and September 30 exceed nine micrograms per liter during two consecutive years.

|   (c) Of the total phosphorus loading of 241 pounds per year specified in section (1) of this rule, 192 pounds per year will be considered current background and Department reserve and is not available to other sources.

|   (d) The total phosphorus maximum annual loading discharged into Collard Lake may not exceed 123 pounds per year.

**OAR 340-041-0345**  
**Basin-Specific Criteria (Willamette): Water Quality Standards and Policies for this Basin**

[...]

(5)	In order to improve water quality within the Yamhill River subbasin to meet the existing water quality standard for pH, the following special rules for total maximum daily loads, waste load allocations, load allocations and program plans are established:

|   (a) After wastewater control facilities and program plans the EQC approved under this rule are completed, and no later than June 30, 1994, no activities may be allowed, and no wastewater may be discharged to the Yamhill River or its tributaries, without the EQC’s authorization, that cause the monthly median concentration of total phosphorus to exceed 70 ug/1 as measured during the low flow period between approximately May 1 and October 31 of each year;

[3.4.8.1]: https://secure.sos.state.or.us/oard/viewSingleRule.action?ruleVrsnRsn=267395
[3.4.8.2]: https://oregon.public.law/rules/oar_340-041-0225

####	Total Phosphorus Status Definitions

Total phosphorus status assessment results are reported and presented in the following way:

*	__Attaining__: When there are no excursions of the applicable TMDL target during a status period.

*	__Not Attaining__: When there is one or more excursion of the applicable TMDL target during a status period.

*	__Unassessed__: When there are no results available or when there are results but no applicable TMDL target to evaluate attainment against. Under these circumstances, the reasons for unassessed status are reported either as “No Results” for no available results or as “No TMDL Target” for no TMDL target.

### Total Suspended Solids

####	Total Suspended Solids Total Maximum Daily Load Targets

```{r tss-tmdl-setup, include=FALSE}

# TSS TMDL SUMMARY 
tbl.tmdls.tss <- tmdl_table %>%
  dplyr::filter(pollutant_name_AWQMS == "Total suspended solids") %>% 
  dplyr::select(TMDL_name, TMDL_issue_year, wq_limited_parameters) %>% 
  dplyr::group_by(TMDL_name, TMDL_issue_year) %>% 
  dplyr::summarise(`303(d) Listing Parameter`=paste0(unique(wq_limited_parameters), collapse = ", ")) %>% 
  dplyr::rename(`TMDL Document Name` = TMDL_name,
                `Year TMDL Issued` = TMDL_issue_year)

# TSS TABLE FOR EACH TMDL DOC
tmdls.name.tss <- sort(unique(tbl.tmdls.tss$`TMDL Document Name`))
# i <- "Tualatin Subbasin TMDL and WQMP"

```

Oregon does not have explicit water quality standards for total suspended solids (TSS); however, TSS has been identified as a pollutant that contributes to excursions of water quality standards and impairment of one or more beneficial uses. Often the excursions are for water quality standards established for sediment, metals, or other toxic chemicals.

In this report, we evaluated status for total suspended solids in the waterbodies where a Total Maximum Daily Load (TMDL) has been established and identified total suspended solids as a pollutant with specific concentration targets. `r tbls(name="tbl.tmdls.tss", display="cite")` summarizes the TMDLs evaluated in this report with TSS concentration targets. Table 18 through Table 21 summarizes the specific TSS targets in each TMDL including where the target applies, the 303(d) water quality limited parameters, the statistical base for each TMDL target, and the applicable calendar period when the TMDL target applies.

```{r TMDL-TSS,  echo=FALSE, results='asis'}

if(NROW(tbl.tmdls.tss) > 0){
  print(knitr::kable(tbl.tmdls.tss, format = "pandoc", padding = 2, 
                     caption = tbls(name="tbl.tmdls.tss", 
                                    caption=paste0("Summary of TMDLs with total suspended solids targets that were evaluated in this report."))))
}

for (i in 1:length(tmdls.name.tss)){
  
  tmdls.doc.df_1 <- tmdl_table %>%
    dplyr::filter(pollutant_name_AWQMS == "Total suspended solids") %>%  
    dplyr::filter(TMDL_name == tmdls.name.tss[i])
  
  year <- unique(tmdls.doc.df_1$TMDL_issue_year)
  
  tmdls.doc.df_2_tss <- tmdls.doc.df_1 %>% 
    dplyr::select(geo_description, wq_limited_parameters, target_text, target_stat_base, period) %>% 
    dplyr::rename(`Geographic Area` = geo_description,
                  `303(d) Listing Parameter` = wq_limited_parameters,
                  `TSS Target Concentration mg/L` = target_text,
                  `Statistical Base` = target_stat_base,
                  `Applicable Period` = period)
  
  if(NROW(tmdls.doc.df_2_tss) > 0){
  print(knitr::kable(tmdls.doc.df_2_tss, format = "pandoc", padding = 2, 
                     caption = tbls(name = paste0("tmdls.doc.df_2_tss", tmdls.name.tss[i]),
                                    caption = paste0("Total suspended solids targets in ", tmdls.name.tss[i], " (DEQ ", year, ")."))))

  }
} 


```

####	 Total Suspended Solids Status Definitions

Total suspended solids status assessment results are reported and presented in the following way:

*	__Attaining__: When there are no excursions of the applicable TMDL target during a status period.

*	__Not Attaining__: When there is one or more excursion of the applicable TMDL target during a status period.

*	__Unassessed__: When there are no results available or when there are results but no numeric applicable TMDL target to evaluate attainment against. Under these circumstances, the reasons for unassessed status are reported either as “No Results” for no available results or as “No TMDL Target” for no TMDL target.

## Water Quality Trend Evaluation

### Assessment Units

Water quality trends were evaluated at monitoring stations only. 

### Trend Result Categories and Definitions

The water quality trends at stations are reported using the following categories:

* __Improving__: When the result demonstrates a statistically significant trend in advancement of water quality conditions.

* __Degrading__: When the result shows a statistically significant trend in deterioration of water quality conditions.

* __Steady__: When the result has a statistically significant slope that equals zero, which indicates neither improving or degrading in water quality conditions.

* __No Significant Trend__: When there is no consistent overall trend.

* __Insufficient Data__: When there are an insufficient number of results available to assess trend. The trends analysis requires water quality results in the same month for at least eight different years over the entire twenty-year analysis period.

### Parameters Evaluated

DEQ calculated trends for bacteria, dissolved oxygen, pH, temperature, total phosphorus, and total suspended solids. 

### Seasonal Kendall Test

A Seasonal Kendall test (Hirsch et al., 1982, Hirsch and Slack, 1984, and Helsel and Hirsch, 2002) was used for the trend evaluation. A Seasonal Kendall test is a nonparametric method used to test for a monotonic trend and can account for the influence of seasonal fluctuations by calculating a Mann-Kendall test (Mann, 1945) on each defined season separately. A season can be any time period. In this analysis each calendar month defined a season. Multiple observations within any given month were collapsed into a single value using the median. After computing the Mann-Kendall for each season, the seasonal statistics are summed, and the variance and Z statistic are computed.

For each parameter at each station where there were sufficient data to evaluate trend, the null hypothesis is that there is no monotonic trend over time. The alternative hypothesis is that for one or more seasons, there is an upward, downward, or steady monotonic trend over time. The null hypothesis is rejected (and we determine there is a trend) if the Z statistic (two-tailed p value) <= 0.20.

A trend assessment using Seasonal Kendall cannot be made at a monitoring station unless the results there have an underlying regularity and there is sufficient data over time. We did not attempt to calculate trend unless there were water quality results in the same month for at least eight different years over the entire twenty-year analysis period. We define “results” as a water quality observation or a calculated summary in the statistical units of the water quality criteria (i.e. geomean or 7-day average daily maximum). If there were insufficient data, “Insufficient Data” is assigned as the result. At stations with sufficient data, a significant positive, negative, or steady trend was determined across all seasons and years when the significance of the trend slopes had a two-tailed p <= 0.20. “Improving” or “Degrading” are assigned to positive or negative slopes depending on the water quality standards and if increasing or decreasing values were an improvement or derogation of water quality. For example, a positive result (increasing value with time) is considered an improving trend for dissolved oxygen but a degrading trend for temperature. A steady trend had a slope equal to zero. “No significant Trend” is assigned when the null hypothesis is not rejected and indicates there is no consistent overall trends during the evaluation period.

Because pH has a high criteria and a low criteria, an improving trend could be associated with a positive or negative seasonal trend slope in the data, depending on where the data is trending from. To address this, improving and degrading trends are defined uniquely for pH. An improving trend is assigned when the data is trending toward the center point between the high and low pH criterion. Data is determined to be trending toward the center of the criterion when the difference between the data and the center of the criterion is smaller at the end of the analysis period than the beginning of that period.

## Watershed Restoration or Protection Actions

To summarize actions taken to restore or protect watersheds and water quality, we summarized on-the-ground treatments implemented and reported to OWEB’s  [Oregon Watershed Restoration Inventory][3.1.7] (OWRI). OWRI is a repository for a significant number of actions implemented in Oregon but it does not capture all restoration or protection actions. In particular projects funded by the United States Farm Bill and many USFS and BLM projects are not included. Typically treatments reported to OWRI were implemented as part of an OWEB grant funded project. DEQ also requires federal 319 grant recipients to report outputs to OWRI. There are over 130 unique treatments identified in OWRI. The various treatments are grouped broadly into the following activity types: fish passage, fish screening, instream habitat, instream flow, riparian, road, upland, and urban. For this report we summarized the number of treatments completed in each of the status periods and the total over the twenty-year period of analysis. For each status period, only treatments completed within the four-year period counted towards the total for that period. The year the project was completed was used for multi-year projects. The totals are reported in the Appendices by subbasin for each activity type and treatment.

# Results

## Statewide

```{r stateIntro, include = TRUE, results = 'asis', fig.cap = cap_list, eval.after = 'fig.cap'}

au_types <- unique(state_param_sum_au$AU_Type)
n_au_ids <- length(unique(state_param_sum_au$AU_ID))
n_au_types <- length(unique(state_param_sum_au$AU_Type))
n_stations <- length(unique(state_param_sum_stn$MLocID))
parameters <- odeqstatusandtrends::AWQMS_to_standard(unique(state_param_sum_au$Char_Name))
n_params <- length(unique(state_param_sum_au$Char_Name))
list_fun <- function(x){paste(x, collapse = "s', '")}
cap_list <- list()

cat(paste0("Available data were sufficient to assess status and/or trend at ", n_stations, " stations within the state. These stations were located across ", n_au_ids, " assessment units consisting of '", list_fun(au_types[1:(n_au_types - 1)]), "s' and '", list_fun(au_types[n_au_types]), "s'. Data for ", 
           gsub("'", "", 
                paste0(paste(parameters[1:(n_params - 1)], collapse = "', '"), "' and '", paste(parameters[n_params], collapse = "', '")
                       , "'")
           ), " were available for analysis and included in this report. The following section summarizes the results of the state-wide analysis.\n\n"))

```

The map in `r figs(name = "query_map", display="cite")` shows the locations of all of the stations that were queried across the state.

```{r stations_map, include=FALSE}

HUC_shp <- rgdal::readOGR(dsn = "N:/Status_and_Trend_Reports/GIS", layer = 'Report_Units_HUC08', integer64="warn.loss", verbose = FALSE, stringsAsFactors = FALSE)
basin_names <- sort(unique(HUC_shp$REPORT))

stations_AWQMS <- odeqstatusandtrends::get_stations_AWQMS(HUC_shp)
huc_names <- unique(stations_AWQMS[,c("HUC8", "HUC8_Name")]) %>% dplyr::filter(HUC8_Name != "-9999")

HUC_shp <- sf::st_as_sf(HUC_shp)
HUC_shp <- sf::st_transform(HUC_shp, 4326)

if(!file.exists(paste0(state_map_dir, "Oregon_query_stations.png"))){
  query_map <- leaflet::leaflet(stations_AWQMS, options = leaflet::leafletOptions(zoomControl = FALSE)) %>% 
    leaflet::addProviderTiles("Esri.NatGeoWorldMap") %>% 
    leaflet::addPolygons(data = HUC_shp, fill = FALSE, opacity = 1, weight = 1.5, color = "black") %>% 
    leaflet::addCircleMarkers(lng = ~Long_DD, lat = ~Lat_DD, stroke = TRUE, weight = 1, opacity = 1, fillOpacity = 1, radius = 1.5,
                              color = "black", fillColor = "green")
  
  mapview::mapshot(query_map, file = paste0(state_map_dir, "Oregon_query_stations.png"), 
                   remove_controls = c("zoomControl", "layersControl"))
}

```

`r paste0("![", figs(name = "query_map", caption = "All stations queried across the state"), "](", paste0(state_map_dir, "Oregon_query_stations.png"), ")")`

```{r stateResults, include = TRUE, results = 'asis', fig.cap = cap_list, eval.after = 'fig.cap'}

cat("### Parameter Summary Maps\n\n")
# fignum <- 1

for(i in unique(state_param_sum_stn$Char_Name)){
  if(i != "pH"){
    parameter_name <- odeqstatusandtrends::simpleCap(i)
  } else {parameter_name <- "pH"}

  
  if(!file.exists(paste0(state_map_dir, "Oregon_", gsub(",| ", "_", i), ".png"))){
    
    wql_streams_lines_i <- dplyr::filter(state_wql_streams_lines, Char_Name == i)
    wql_streams_ws_i <- dplyr::filter(state_wql_streams_ws, Char_Name == i)
    
    map_df <- state_param_sum_stn %>% dplyr::filter(Char_Name == i) %>% dplyr::mutate(color = dplyr::if_else(!!status_current %in% c("Unassessed", "Insufficient Data"),
                                                                                                         "lightgray",
                                                                                                         dplyr::if_else(!!status_current == "Not Attaining",
                                                                                                                        "orange",
                                                                                                                        "green")
    ))
    
    map <- leaflet::leaflet(options = leaflet::leafletOptions(zoomControl = FALSE)) %>% 
      leaflet::addProviderTiles("Esri.NatGeoWorldMap") %>%
      leaflet::addPolygons(data = wql_streams_ws_i,
                            opacity = 1,
                            weight = 2,
                            color = "#ff33be",
                           fillOpacity = 0.1,
                           fillColor = "#ff33be") %>% 
      leaflet::addPolylines(data = wql_streams_lines_i,
                            opacity = 1,
                            weight = 2,
                            color = "#ff33be"
      ) %>%
      leaflet::addPolygons(data = HUC_shp, fill = FALSE, opacity = 1, weight = 1.5, color = "black") %>%
      leaflet::addCircleMarkers(data = map_df, lng = ~Long_DD, lat = ~Lat_DD,
                                fillColor = ~color, stroke = TRUE, weight = 0.5,
                                opacity = 1, fillOpacity = 1, color = 'black', radius = 2.5) %>% 
      leaflet::addControl(position = "bottomright", className = "legend",
                          html = sprintf('<html><body><div style="opacity:0.95">
                                        <img width="150" height="140" src="data:image/png;base64,%s">
                            </div></body></html>', lgnd)) %>% 
      leaflet::addControl(html = paste('<div style="opacity:0.95; background:white; padding:0px 6px; border-radius: 8px; font-size:18px"><b>', 
                                       "Oregon", parameter_name, "Status</b></div>"), 
                          position = "topleft", className = "map_title")
    
    mapview::mapshot(map, file = paste0(state_map_dir, "Oregon_", gsub(",| ", "_", i), ".png")
                     # , remove_controls = c("zoomControl", "layersControl")
    )
  }
  
  cat(paste0("![", figs(name = paste0("state_", i, "_map"), 
                        caption = paste0("Summary map of the ", complete_years[17], "–", complete_years[20]," status of ", i, " monitoring stations across the state")),
             "](", state_map_dir, "Oregon_", gsub(",| ", "_", i), ".png)"), "\n")
  # cat()
  # fignum <- fignum + 1
  cat("\n\n")
}

cat("### Status\n\n")

cat(paste0(tbls("au_sum", display = 'cite')," shows the number of attaining, not attaining, and unassessed assessment units by parameter for the ", complete_years[17], "–", complete_years[20]," status period.\n\n"))

au_sum <- state_param_sum_au %>% dplyr::group_by(Char_Name) %>% 
  dplyr::summarise(Attaining = sum(status_2016_2019 == "Attaining"),
                   'Not Attaining' = sum(status_2016_2019 == "Not Attaining"),
                   Unassessed = sum(status_2016_2019 == "Unassessed")) %>% 
  dplyr::mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  dplyr::rename(Pollutant = Char_Name)

# cat(tbls(name = "au_sum", caption = "Summary of assessment unit status across the state."))

knitr::kable(au_sum, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "au_sum", caption = "The number of assessment units in each status category by parameter for the ", complete_years[17], "–", complete_years[20]," status period across the state.")
) %>% table_style()

cat("\n\n")

au_sum_plot <- ggplot2::ggplot(reshape2::melt(au_sum, id.vars = "Pollutant", variable.name = "Status"))+
  ggplot2::geom_bar(aes(x = Pollutant, y = value, fill = Status), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_not_attaining, fill = "Not Attaining"), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_unassessed, fill = "Unassessed"), stat = "identity", position = "dodge")+
  ggplot2::xlab("Pollutant")+
  ggplot2::ylab("# of Assessment Units")+
  ggplot2::scale_fill_manual(values = c("Attaining" = "forestgreen", "Not Attaining" = "orange", "Unassessed" = "gray"))+
  ggplot2::theme_bw()+
  ggplot2::ggtitle("Count of Assessment Unit Status", subtitle = "Summarized by Parameter")

au_sum_plot
cap_list[[1]] <- figs(name = paste0("state_au_sum_plot"), caption = paste0("Summary plot showing the number of assessment units in each status category by parameter for the ", complete_years[17], "–", complete_years[20]," status period across the state."))
# cat(paste0("![", figs(name = paste0("state_au_sum_plot"), caption = paste0("Summary plot of assessment unit status across the state by parameter.")),
#            "]()"))

cat(paste0("\n\n", tbls("au_type_sum", display = 'cite')," contains a summary of the number of attaining, not attaining, and unassessed assessment units by parameter and assessment unit type for the ", complete_years[17], "–", complete_years[20]," status period.\n\n"))

au_sum_type <- state_param_sum_au %>% dplyr::group_by(AU_Type, Char_Name) %>% 
  dplyr::summarise(Attaining = sum(status_2016_2019 == "Attaining"),
                   'Not Attaining' = sum(status_2016_2019 == "Not Attaining"),
                   Unassessed = sum(status_2016_2019 == "Unassessed")) %>% 
  dplyr::mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  dplyr::rename("AU Type" = AU_Type, Pollutant = Char_Name)

# cat(tbls(name = "au_type_sum", caption = "Statewide status summary of assessment units by type."))

knitr::kable(au_sum_type, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "au_type_sum", caption = paste0("The number of assessment units in each status category by parameter for the ", complete_years[17], "–", complete_years[20]," status period across the state."))
             )%>% table_style()


cat("\n\n")

cat(paste0("\n\n", tbls("stn_sum", display = 'cite') ," summarizes the number of attaining, not attaining, and unassessed stations by parameter for the ", complete_years[17], "–", complete_years[20], " status period across the state.\n\n"))

stn_sum <- state_param_sum_stn %>% dplyr::group_by(Char_Name) %>% 
  dplyr::summarise(Attaining = sum(status_2016_2019 == "Attaining"),
                   
                   "Not Attaining" = sum(status_2016_2019 == "Not Attaining"),
                   Unassessed = sum(status_2016_2019 == "Unassessed"))%>% 
  dplyr::mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  dplyr::rename(Pollutant = Char_Name)

# cat(tbls(name = "stn_sum", caption = "Summary of the status of stations across the state."))

knitr::kable(stn_sum, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "stn_sum", caption = paste0("Summary of the ", complete_years[17], "–", complete_years[20]," status at monitoring stations across the state."))
) %>% table_style()

cat("\n\n")

stn_sum_plot <- ggplot2::ggplot(reshape2::melt(stn_sum, id.vars = "Pollutant", variable.name = "Status"))+
  ggplot2::geom_bar(aes(x = Pollutant, y = value, fill = Status), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_not_attaining, fill = "Not Attaining"), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_unassessed, fill = "Unassessed"), stat = "identity", position = "dodge")+
  ggplot2::xlab("Pollutant")+
  ggplot2::ylab("# of Stations")+
  ggplot2::scale_fill_manual(values = c("Attaining" = "forestgreen", "Not Attaining" = "orange", "Unassessed" = "gray"))+
  ggplot2::theme_bw()+
  ggplot2::ggtitle("Count of Monitoring Station Status", subtitle = "Summarized by Parameter")

stn_sum_plot
cap_list[[2]] <- figs(name = paste0("state_stn_sum_plot"), caption =paste0("The number of stations in each status category by parameter for the ", 
                                       complete_years[17], "–", complete_years[20],
                                       " status period across the state."))
# cat(paste0("![", figs(name = paste0("state_stn_sum_plot"), caption = paste0("Summary plot of station status across the state by parameter.")),
#            "]()"))

# fignum <- fignum + 1

cat("\n\n")
cat("### Trend\n\n")

cat(paste0("\n\nA summary of the trends across parameters is shown in ", tbls("stn_trend_sum", display = 'cite'),". Note that trend requires significantly more data than status and may result in many stations with sufficient data for assessing status, but insufficient data for assessing trend.\n\n"))

stn_sum <- state_param_sum_stn %>% dplyr::group_by(Char_Name) %>% 
  dplyr::summarise(Improving = sum(trend == "Improving"),
                   
                   Degrading = sum(trend == "Degrading"),
                   Steady = sum(trend == "Steady"),
                   "No Significant Trend" = sum(trend == "No Significant Trend"),
                   "Insufficient Data" = sum(trend == "Insufficient Data"),
  ) %>% 
  dplyr::mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  dplyr::rename(Pollutant = Char_Name)

# cat(tbls(name = "stn_trend_sum", caption = "Statewide summary of trends at stations across the state."))

knitr::kable(stn_sum, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "stn_trend_sum", caption = "Statewide summary of trends at stations across the state.")
) %>% table_style()

cat("\n\n")

# cat("## OWRI Watershed Restoration Actions")
# cat("\n\n")

# owri_basin <- owri_summary %>% dplyr::group_by(ActivityType, Treatment_Unit) %>% summarise_at(colnames(owri_summary)[5:10], sum)
# action_df <- owri_basin[owri_basin$Total != 0,]
# actions <- unique(action_df$ActivityType)
# n_action <- length(actions)
# n_units <- length(unique(action_df$Treatment_Unit))
# 
# cat(paste0("According to the Oregon Watershed Restoration Inventory (OWRI), ", n_action, " types of restoration actions have been implemented across the ", basin, " basin including '", paste(actions[1:(n_action-1)], collapse = "', '"), "' and '", paste(actions[n_action], collapse = "', '"), "' activities encompassing ", n_units, " different forms of treatment units. ", tbls(paste0(basin, "_owriTab"), display = "cite"), " summarizes reported treatment outputs reported to the Oregon Watershed Restoration Inventory (owri) for numerous watershed restoration projects within the  ", basin, " basin. Basin Treatment summaries are grouped into yearly periods. The year refers to the year the project was completed."))
#   
# cat("\n\n")
# 
# colnames(owri_basin) <- sapply(gsub("_", " ", colnames(owri_basin)), simpleCap, USE.NAMES = FALSE)
# 
# cat(tbls(name = paste0(basin, "_owriTab"), 
#          caption = paste("Summary of watershed restoration actions implemented and reported to the Oregon Watershed Restoration Inventory in the ",
#                          basin, " basin. Source: OWEB OWRI ", owri_version)
# )
# )
# capnum <- tbls(paste0(basin, "_owriTab"), display = "num")
# 
# t <- knitr::kable(owri_basin, format = table_format, padding = 0, digits = 1, row.names = FALSE
# ) %>% table_style()
# 
# print(t)
# 
# cat("\n\n")

```


```{r Basins, include=FALSE}

basin_output <- NULL
# capnum <- 6

appendix_letter <- list("Black Rock Desert Basin"="A",
                        "Columbia River"="B",
                        "Deschutes Basin"="C",
                        "Goose Lake"="D",
                        "Grande Ronde"="E",
                        "John Day Basin"="F",
                        "Klamath Basin"="G",
                        "Malheur"="H",
                        "Mid-Coast"="I",
                        "Middle Columbia-Hood"="J",
                        "North Coast-Lower Columbia"="K",
                        "Oregon Closed Basins"="L",
                        "Owyhee"="M",
                        "Powder-Burnt"="N",
                        "Rogue Basin"="O",
                        "Sandy"="P",
                        "Snake River"="Q",
                        "South Coast"="R",
                        "Umatilla-Walla Walla-Willow"="S",
                        "Umpqua Basin"="T",
                        "Willamette Basin"="U")

for(i in basin_names){
  
  name <- i
  a.letter <- appendix_letter[[name]]
  
  basin_output <- c(basin_output, knitr::knit_child(input = "state_basin_summary.Rmd", envir = globalenv()))
}

```

`r paste(basin_output, collapse = "\n")`


# Citations

Federal Geographic Data Committee (FGDC). 2012. "Coastal and Marine Ecological Classification Standard FGDC-STD-018-2012". Marine and Coastal Spatial Data Subcommittee.  https://www.fgdc.gov/standards/projects/cmecs-folder/CMECS_Version_06-2012_FINAL.pdf

Helsel, D.R. and R. M. Hirsch. 2002. "Techniques of Water Resources Investigations" in *Statistical Methods in Water Resources*, Book 4, Chapter A3. U.S. Geological Survey. 522 pages.

Hirsch, R.M. and J.R. Slack. 1984. "A nonparametric trend test for seasonal data with serial dependence." *Water Resources Research* 20(6):727-732.

Hirsch, R.M., J.R. Slack and R.A. Smith. 1982. "Techniques of trend analysis for monthly water quality data." *Water Resources Research* 18(1):107-121.

Horton, R.E. 1945. "Erosional development of streams and their drainage basins: hydro-physical approach to quantitative morphology." *Geological Society of America Bulletin* 56(3):275–370.

Mann, H. B. 1945. "Nonparametric test against trend." *Econometrica* 13:245-259.

Oregon Department of Environmental Quality (DEQ). 1991a. "Bear Creek Watershed TMDL." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Rogue-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 1991b. "Clear Lake TMDL." https://www.oregon.gov/deq/FilterDocs/ClearLakeTMDL.pdf

Oregon Department of Environmental Quality (DEQ). 1991c. "TMDLs for the Yamhill River."
https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Willamette-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 1998. "Garrison Lake TMDL." https://www.oregon.gov/deq/FilterDocs/scGarrisonLakeTMDL.pdf

Oregon Department of Environmental Quality (DEQ). 2001. "Umatilla River Basin TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Umatilla-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 2002. "Upper Klamath Lake Drainage TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Klamath-Basin.aspx#2019tmdl

Oregon Department of Environmental Quality (DEQ). 2003. "Snake River Hells Canyon TMDL." https://www.oregon.gov/deq/wq/tmdls/Pages/snakesubbasin.aspx

Oregon Department of Environmental Quality (DEQ). 2006a. "Umpqua Basin TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Umpqua-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 2006b. "Willamette Basin TMDL." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Willamette-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 2007. "Tenmile Lakes TMDL." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-South-Coast-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 2008. "Molalla-Pudding Subbasin TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Willamette-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 2010. "Malheur River Basin TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/malheurtmdl.aspx

Oregon Department of Environmental Quality (DEQ). 2012. "Tualatin Subbasin TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Willamette-Basin.aspx

Oregon Department of Environmental Quality (DEQ). 2013. "Data validation criteria for water quality parameters measured in the field. DEQ04-LAB-0003-QAG Version5.0." http://www.oregon.gov/deq/FilterDocs/DataQualMatrix.pdf

Oregon Department of Environmental Quality (DEQ). 2018. "Integrated Report Improvements, Use of Censored Data." https://www.oregon.gov/deq/FilterDocs/iriCensoredData.pdf

Oregon Department of Environmental Quality (DEQ). 2019a. "Upper Klamath and Lost River Subbasin Nutrient TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Klamath-Basin.aspx#2019tmdl

Oregon Department of Environmental Quality (DEQ). 2019b. "Upper Klamath and Lost Subbasins Temperature TMDL and WQMP." https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Klamath-Basin.aspx#2019tmdl

Oregon Department of Environmental Quality (DEQ). 2020. "Methodology for Oregon’s 2018 Water Quality Report and List of Water Quality Limited Waters." https://www.oregon.gov/deq/wq/Documents/irMethodologyF1820.pdf

R Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/

Strahler, A.N. 1952. "Hypsometric (area-altitude) analysis of erosional topology." *Geological Society of America Bulletin* 63(11):1117–1142.