---
author: "Colin Donald"
date: "`r format(Sys.Date(), '%m/%d/%Y')`"
output: 
  word_document: 
    fig_caption: yes
    keep_md: yes
    reference_docx: N:/Status_and_Trend_Reports/Report_Files/Report_Template.docx
    toc: yes
    fig_width: 12
    fig_height: 6
  html_document:
    mode: selfcontained
    number_sections: yes
    template: N:/Status_and_Trend_Reports/Report_Files/report_template.html
    toc: yes
    toc_depth: 5
    toc_float: 
      collapsed: true
      smooth_scroll: true
    fig_width: 12
  pdf_document:
    toc: yes
always_allow_html: yes
# params: 
#   basin: "placeholder"
#   param_sum: "placeholder"
#   param_sum_au: "placeholder"
#   owri_summary: "placeholder"
#   owri_version: "placeholder"
#   complete_years: "placeholder"
#   hucs: "placeholder"
#   table_format: "placeholder"
---

```{r setup, include=FALSE}

options(knitr.duplicate.label = 'allow')
options(tinytex.verbose = TRUE)

knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning=FALSE,
                      error = FALSE,
                      cache = FALSE,
                      include = TRUE,
                      fig.keep='all',
                      fig.path=paste0(out_dir, "/Figures/"),
                      fig.width = 12, 
                      fig.height = 6)

library(dplyr)
library(knitr)
library(kableExtra)
library(captioner)
library(reshape2)
library(leaflet)
library(mapview)
library(readxl)
library(odeqstatusandtrends)
library(odeqassessment)
library(sf)
library(rgdal)
library(ggplot2)

# param_sum <- params$param_sum
# param_sum_au <- params$param_sum_au
# basin <- params$basin
# complete_years <- params$complete_years
# hucs <- params$hucs
# table_format <- params$table_format
# name <- "Willamette"
year <- "2019"
start.date = "1999-01-01"
end.date = "2018-12-31"
complete_years <- c(as.integer(substr(start.date, start = 1, stop = 4)):as.integer(substr(end.date, start = 1, stop = 4)))
state_project_dir <- paste0("N:/Status_and_Trend_Reports/", year, "-Revision/")

figs <- captioner(prefix="Figure")
tbls  <- captioner(prefix="Table")
eqns <- captioner(prefix="Equation")

load(file = paste0(state_project_dir, "Oregon_param_summary_by_station.RData"))
load(file = paste0(state_project_dir, "Oregon_param_summary_by_AU.RData"))

state_param_sum_stn <- state_param_sum_stn %>% dplyr::filter(!is.na(AU_ID))
state_param_sum_stn <- state_param_sum_stn %>% dplyr::filter(AU_ID != "")
state_param_sum_stn$Char_Name <- AWQMS_to_standard(state_param_sum_stn$Char_Name)
state_param_sum_au <- state_param_sum_au %>% dplyr::filter(!is.na(AU_ID))
state_param_sum_au <- state_param_sum_au %>% dplyr::filter(AU_ID != "")
state_param_sum_au$Char_Name <- AWQMS_to_standard(state_param_sum_au$Char_Name)

state_param_sum_stn$AU_Type <- if_else(grepl("_SR_", state_param_sum_stn$AU_ID),
                             "Stream",
                             if_else(grepl("_LK_", state_param_sum_stn$AU_ID),
                                     "Lake",
                                     if_else(grepl("_WS_", state_param_sum_stn$AU_ID),
                                             "Watershed Unit",
                                             if_else(grepl("_EB_", state_param_sum_stn$AU_ID),
                                                      "Estuary or Bay",
                                                     if_else(grepl("_CL_", state_param_sum_stn$AU_ID),
                                                             "Coastline",
                                                             NA_character_
                                                     )
                                             )
                                     )
                             )
)
state_param_sum_au$AU_Type <- if_else(grepl("_SR_", state_param_sum_au$AU_ID),
                             "Stream",
                             if_else(grepl("_LK_", state_param_sum_au$AU_ID),
                                     "Lake",
                                     if_else(grepl("_WS_", state_param_sum_au$AU_ID),
                                             "Watershed Unit",
                                             if_else(grepl("_EB_", state_param_sum_au$AU_ID),
                                                      "Estuary or Bay",
                                                     if_else(grepl("_CL_", state_param_sum_au$AU_ID),
                                                             "Coastline",
                                                             NA_character_
                                                     )
                                             )
                                     )
                             )
)
state_param_sum_stn[state_param_sum_stn$AU_ID == "Sru Lake", "AU_Name"] <- "Sru Lake"
state_param_sum_stn[state_param_sum_stn$AU_ID == "Sru Lake", "AU_Type"] <- "Lake"
state_param_sum_au[state_param_sum_au$AU_ID == "Sru Lake", "AU_Name"] <- "Sru Lake"
state_param_sum_au[state_param_sum_au$AU_ID == "Sru Lake", "AU_Type"] <- "Lake"

status_current <- as.symbol(colnames(state_param_sum_stn)[grep("trend", colnames(state_param_sum_stn)) - 1])

basin_intro <- FALSE

# project_dir <- paste0('N:/Status_and_Trend_Reports/2019/2019-', basin, '/')

# area <- readOGR(dsn = gis_dir, layer = 'Report_Units_HUC08', integer64="warn.loss", verbose = FALSE, stringsAsFactors = FALSE)
# area <- area[area$REPORT %in% c(name), ]
# area <- sf::st_as_sf(area)
# area <- st_transform(area, 4326)

state_wql_streams <- sf::st_read(
    dsn = "N:/Agriculture/Status_and_Trend_Analysis/R_support_files",
    layer = "WQL_Streams_2012",
    # query = paste0("SELECT * FROM WQL_Streams_2012 WHERE HUC_4TH_CO IN ('",
    #                paste(unique(param_sum$HUC8), collapse = "', '"), "')"),
    stringsAsFactors = FALSE, quiet = TRUE
  )
state_wql_streams$Char_Name <- unlist(sapply(state_wql_streams$POLLUTANT, AWQMS_Char_Names, USE.NAMES = FALSE))
state_wql_streams$Char_Name <- AWQMS_to_standard(state_wql_streams$Char_Name)
state_wql_streams <- sf::st_zm(state_wql_streams, what = "ZM")
state_wql_streams <- st_transform(state_wql_streams, 4326)
state_wql_streams <- filter(state_wql_streams[, c("STREAM_NAM", "SEGMENT_ID", "SEASON", "Char_Name", "LISTING_ST", "TMDL_INFO")], Char_Name %in% unique(state_param_sum_stn$Char_Name))
state_wql_streams_shp <- state_wql_streams %>% group_by(Char_Name) %>% summarise(geometry = st_union(geometry))
# wql_streams <- wql_streams[lapply(wql_streams$`_ogr_geometry_`, length) != 0,]

if(!dir.exists(paste0(state_project_dir, "Statewide Maps"))) {dir.create(paste0(state_project_dir, "Statewide Maps"))}

state_map_dir <- paste0(state_project_dir, "Statewide Maps/")

lgnd <- base64enc::base64encode("//deqhq1/WQNPS/Status_and_Trend_Reports/Figures/map_overview_legend.png")

table_style <- function(x){
  kableExtra::kable_styling(x, latex_options = "repeat_header", repeat_header_continued = T,
                            bootstrap_options = c("striped", "hover", "condensed", "responsive"))
}

```

---
title: "`r paste(year, 'Oregon Statewide Status and Trends Report')`"
---

# Introduction

This report presents the results of a statewide water quality status and trends analysis as well as a summary of best management practices implemented. The analysis is intended to answer these four questions:

*	What is the status of water quality in Oregon? Are waterbodies attaining water quality standards for bacteria, dissolved oxygen, pH, and temperature? 
*	Where applicable, are Total Maximum Daily Load (TMDL) targets established for total phosphorus or total suspended solids being attained? 
*	What are the trends in water quality?
* What watershed restoration or protection actions have been implemented?

DEQ conducted this analysis by assembling surface water quality data and information about best management practices implemented from readily accessible public databases, comparing these water quality data to the appropriate Oregon water quality standards or TMDL targets, and determining the status and trends where data and information of sufficient quality and quantity are available. Results are summarized for each of the 19 administrative basins in Oregon as well as the Columbia and Snake Rivers.

A webmap tool is also available on DEQ’s website to search for and review results. The current URL for this website is https://www.oregon.gov/deq/wq/programs/Pages/wqstatustrends.aspx.

The results of this analysis informs DEQ, other state and federal agencies, and the public on the condition of waters and if TMDLs are being achieved; if water quality is improving or degrading; the pace of improvement or degradation; what actions, if any, are being taken to improve water quality, and where water quality data are and are not being collected.

# Analysis Area and Tribal Waters

Only those waters that are under the State of Oregon’s jurisdiction are evaluated in this report. The State of Oregon communicates with Oregon's nine federally-recognized Tribes in a government-to-government relationship to develop and implement agency programs that may affect the Tribes. Oregon DEQ does not assume jurisdiction to designate beneficial uses, apply water quality standards, list impaired waters, or develop TMDLs within tribal territory, except by cooperative agreement with Tribal governments. In 2017, DEQ conducted a water quality standards georeferencing project to map the extent of designated beneficial uses, water quality standards, and assessment units for reporting of the Clean Water Act section 303(d) impaired waters list. As part of this effort, DEQ collected the best available information on the location of Tribal Reservation and off Reservation Trust Lands. For this analysis, DEQ only assessed waterbodies and data collected outside of Tribal Reservation or off Reservation Trust Land boundaries.

# Methods

## Data Sources

Water quality data were retrieved from DEQ's [Ambient Water Quality Monitoring System (AWQMS)][3.1.1] which integrates DEQ water quality data with other publically available data sources (including the now retired DEQ LASAR database); the [Water Quality Portal][3.1.2]) which includes data from the U.S. Environmental Protection Agency ([WQX/STORET][3.1.3]) database, USGS's [NWIS][3.1.4], and other federal agencies, Tribes, and various third parties; NOAA’s [National Estuarine Research Reserve System][3.1.5]; [EIM][3.1.6] (Washington Department of Ecology database); and data obtained during DEQ’s Integrated Report “call for data” process. 

Information about watershed improvement projects and the associated on the ground treatments that were implemented were obtained from the [Oregon Watershed Restoration Inventory][3.1.7] (OWRI) database maintained by the Oregon Watershed Enhancement Board (OWEB).

[3.1.1]: https://www.oregon.gov/deq/wq/pages/wqdata.aspx
[3.1.2]: https://www.waterqualitydata.us
[3.1.3]: https://www.epa.gov/waterdata/water-quality-data-wqx
[3.1.4]: https://waterdata.usgs.gov/nwis
[3.1.5]: https://coast.noaa.gov/nerrs
[3.1.6]: https://ecology.wa.gov/Research-Data/Data-resources/Environmental-Information-Management-database
[3.1.7]: https://www.oregon.gov/oweb/data-reporting/Pages/owri.aspx

## QA/QC Requirements

All data used in the Status and Trends Report must have a project plan (Quality Assurance Project Plan (QAPP) or similar) or use widely accepted sampling and analysis methods. Internal DEQ and data collected through the Volunteer Monitoring Program must have a Data Quality Level (DQL) of A or B. Data quality levels for parameters measured in the field are assigned following [DEQ’s Data Quality Matrix][3.2.1] (DEQ 2013). The data quality matrix defines the accuracy and precision criteria for field audits and calibration verifications respectively. Analytical or laboratory analyzed data are assigned data quality levels based on quality control and assurance protocols and internal data review. Data submitted through the integrated report call for data or originally obtained from the Water Quality Portal were included if they had a result status of “Final”, “Accepted”, or “Validated”. Any data with a result measure qualifier code that indicated problems with the data were removed. We relied on the quality control checks implemented by OWEB for treatment data obtained from OWRI.

Additional checks included reviewing for inconsistences in the station description and station location (latitude and longitude). Any inconsistences were corrected. If the sampling location could not be determined, data at that station were not used. Multiple stations that appear to have the same data were also reviewed and corrected. This can occur when the data is in two different databases with different station IDs assigned. Results in units of ug/L were converted to mg/L and temperature data measured in degrees Fahrenheit were converted to degrees Celsius.

For samples that were taken for the purpose of auditing the field data (often called replicates or duplicates) the field samples were prioritized and the replicate removed if the DQL for both the field sample and duplicate were the same. If the DQLs were different the sample with the higher DQL was used.

For samples that appear to be replicates or samples made at various depths (i.e. the sample date/time, sample location, and sample parameter were the same) but were not labeled as replicates or depth samples, we took the mean of the samples.

[3.2.1]: http://www.oregon.gov/deq/FilterDocs/DataQualMatrix.pdf

## Period of Analysis

Water quality data collected over a twenty year period starting `r format(lubridate::ymd(start.date), format="%B %d, %Y")` and ending on `r format(lubridate::ymd(end.date), format="%B %d, %Y")` were retrieved from the data sources identified in Section 3.1.

For assessment of status, the twenty year period of analysis was divided into five shorter periods with each shorter period spanning four years. Only data collected within the four year period were used to determine status for that period. The five status periods are defined by the following calendar years:

*	1999 – 2002
*	2003 – 2006
*	2007 – 2010
*	2011 – 2014
*	2015 - 2018

Trends were evaluated over the entire twenty year period. Minimum data requirements to assess trend are discussed in Section 3.5.

## Water Quality Status Assessment

The status assessment is an evaluation of water quality data to determine if a waterbody attains water quality standards or TMDL targets. An attainment assessment was made for bacteria (*E. coli*, *Enterococcus*, and Fecal Coliform), dissolved oxygen, pH, and temperature in relation to the applicable numeric water quality criterion. For some waterbodies the applicable water quality criterion for these parameters is a narrative non-numeric criterion. In this situation, status was not determined.

Oregon does not have explicit water quality standards for total phosphorus (TP) or total suspended solids (TSS) however sometimes these parameters are pollutants that contribute to non-attainment of water quality standards. Often the impairment is based on standards established for dissolved oxygen, pH, sediment, or other chemicals. An attainment assessment was made for total phosphorus (TP) or total suspended solids (TSS) where a TMDL target has been established for these parameters. The following sections describe the water quality standards or applicable TMDL targets for each parameter assessed.

### Assessment Units

The water quality status were assessed at monitoring stations and waterbody-based assessment units (AUs). The AUs incorporate the High Resolution National Hydrography (NHDH) framework with environmentally and hydrologically relevant breaks of water bodies, and remain the same over time (fixed units). The NHDH is a digital geospatial dataset that represents the surface water of the entire United States at a scale of 1:24K or better. It is now the national and state hydrologic framework standard, replacing the LLID system. The AUs in this report consist of “Streams”, “Watershed Units”, “Lakes”, “Coastlines” and “Estuary or Bays”.

### Status Reporting and Definitions

The status assessment results are reported and presented in a number of ways. For each station or AU we report the status result in the following way:

* __Attaining__: When results demonstrate attainment of the water quality criteria or TMDL target.
* __Not Attaining__: When results do not attain the water quality criteria or TMDL target.
* __Insufficient Data__: When there are results available but the results do not meet QA/QC objectives including minimum Data Quality Levels (DQLs); or the results do not meet minimum requirements to evaluate attainment of the water quality criteria or TMDL target.
* __Unassessed__: When there are no results available or when there are results but no numeric water quality criteria or TMDL target to evaluate attainment against. The later condition occurs where there are total suspended solids or total phosphorus data available in an area but no TMDL targets established in that area.

We define “results” as a water quality observation or a calculated observation in the statistical units of the water quality criteria (i.e. geomean or 7-day average daily maximum). An "excursion" occurs when a result is worse than the water quality standard or TMDL target. For each parameter and within each status period, we calculate and report on the total number of results, total excursions, the percent excursion (= total excursions / total number of results X 100), and the minimum, maximum, and median excursion result value. Results are also plotted as a timeseries with the applicable water quality standard or TMDL target included on the plot. Excursions are noted.

### Bacteria

#### Water Quality Criteria

Results for bacteria samples were compared to the applicable bacteria criterion as found in [OAR 340-041-0009][3.4.3]. 

OAR 340-041-0009

Bacteria

(1)	Numeric Criteria: Organisms commonly associated with fecal sources may not exceed the criteria in subsections (a)-(c) of this section:

|   (a)	Freshwater contact recreation:

|     (A)	A 90-day geometric mean of 126 E. coli organisms per 100 mL;

|     (B)	No single sample may exceed 406 E. coli organisms per 100 mL.

|   (b)	Coastal water contact recreation, as designated in OAR 340-041-0101, 340-041-220, 340-041-230, 340-041-300 and 340-041-0320:

|     (A)	A 90-day geometric mean of 35 enterococcus organisms per 100 mL;

|     (B)	Not more than ten percent of the samples may exceed 130 organisms per 100 mL.

|   (c)	Shellfish harvesting, as designated in 340-041-0101, 340-041-220, 340-041-230, 340-041-300 and 340-041-0320:

|     (A)	A fecal coliform median concentration of 14 organisms per 100 mL;

|     (B)	Not more than ten percent of the samples may exceed 43 organisms per 100 mL.

(2)	A minimum of five samples in a 90-day period is required for calculating the criteria in sections (1)(a)(A) and (1)(b)(A) and (B) of this rule.

(3)	Raw Sewage Prohibition: No sewage may be discharged into or in any other manner be allowed to enter the waters of the State, unless such sewage has been treated in a manner the Department approved or otherwise allowed by these rules.

(4)	Animal Waste: Runoff contaminated with domesticated animal wastes must be minimized and treated to the maximum extent practicable before it is allowed to enter waters of the State.

(5)	Bacterial pollution or other conditions deleterious to waters used for domestic purposes, livestock watering, irrigation, bathing, or shellfish propagation, or otherwise injurious to public health may not be allowed.

[3.4.3]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68695

#### Assessment Protocol

Bacteria related to fecal sources can impair beneficial uses of water for recreation and fishing use by shellfish harvesting. Oregon has established water quality standards for relevant bacterial indicators for specific designated uses and various water types (`r tbls(name = "bacteriaIndicators", display="cite")`).

The indicators are:

* *E. coli* for contact recreation in freshwater lakes, rivers, and streams;
* *Enterococcus* for contact recreation in coastal marine and estuary waters; and
* Fecal coliform for shellfish harvesting in marine and estuarine waters.

As salinity increases in estuarine waters, *E. coli* tend to die-off while *Enterococci* remain viable. When data and information for the applicable bacterial indicator in a marine, estuarine, or freshwater location are available, the corresponding criteria are applied to assess each use designated for the water.

```{r tbl-bacteria-indicators}

bacteria.indicators.tbl <- data.frame(du=c("Freshwater contact recreation","Coastal water contact recreation","Shellfish harvesting"),
                                      indicator=c("*E. coli*","*Enterococcus*","Fecal coliform"),
                                      critera=c("Geometric mean <= 126","Geometric mean <= 35", "Median <= 14"),
                                      thresh=c("No more than 10% > 406","No more than 10% > 130", "No more than 10% > 43"))

colnames(bacteria.indicators.tbl) <- c("Designated use", 
                                       "Bacterial indicator",
                                       "Criteria metric (CFU / 100 mL)", 
                                       "Threshold Value (CFU / 100 mL)")

knitr::kable(bacteria.indicators.tbl, 
             padding = 0, digits = 1, format = table_format,
             row.names = FALSE,
             caption = tbls(name = "bacteriaIndicators", 
                            caption = "Bacterial Indicators and Criteria."))

```

A geometric mean is calculated on a rolling basis for each 90-day period of data available at a sampling location. A minimum of five samples collected on different days is required to calculate a 90-day rolling geometric mean. The 90-day geometric mean ($GM90$) of bacteria concentration is calculated using `r tbls(name = "eqns-GM90", display="cite")` by taking the nth root of the product of the concentration of each sample collected within a 90-day period for which $n$ ≥ 5.

`r eqns(name = "eqns-GM90", caption = "Geometric Mean Equation.")`

$$GM90 = \sqrt[n]{x_{1}x_{2}...x_{n}}$$  

Where:

$GM90$ = The geometric mean over a 90 day period.

$n$ = number of samples.

$x_n$ = bacteria sample concentration, as number of organisms per 100 mL.

The median sample concentration is calculated for the entire analysis period once there are at least five samples available.

### Dissolved Oxygen

#### Water Quality Criteria

Dissolved oxygen status was assessed by comparing the observed concentration values to the applicable water quality criterion found in [OAR 340-041-0016][3.4.4].

OAR 340-041-0016

Dissolved Oxygen

Dissolved oxygen (DO): No wastes may be discharged and no activities may be conducted that either alone or in combination with other wastes or activities will cause violation of the following standards: The changes adopted by the Commission on January 11, 1996, become effective July 1, 1996. Until that time, the requirements of this rule that were in effect on January 10, 1996, apply:

(1)	For water bodies identified as active spawning areas in the places and times indicated on the following Tables and Figures set out in OAR 340-041-0101 to 340-041-0340: Tables 101B, 121B, and 190B, and Figures 130B, 151B, 160B, 170B, 180A, 201A, 220B, 230B, 260A, 271B, 286B, 300B, 310B, 320B, and 340B, (as well as any active spawning area used by resident trout species), the following criteria apply during the applicable spawning through fry emergence periods set forth in the tables and figures and, where resident trout spawning occurs, during the time trout spawning through fry emergence occurs:

|  (a)	The dissolved oxygen may not be less than 11.0 mg/l. However, if the minimum intergravel dissolved oxygen, measured as a spatial median, is 8.0 mg/l or greater, then the DO criterion is 9.0 mg/l;

|  (b)	Where conditions of barometric pressure, altitude, and temperature preclude attainment of the 11.0 mg/l or 9.0 mg/l criteria, dissolved oxygen levels must not be less than 95 percent of saturation;

|  (c)	The spatial median intergravel dissolved oxygen concentration must not fall below 8.0 mg/l.

(2)	For water bodies identified by the Department as providing cold-water aquatic life, the dissolved oxygen may not be less than 8.0 mg/l as an absolute minimum. Where conditions of barometric pressure, altitude, and temperature preclude attainment of the 8.0 mg/l, dissolved oxygen may not be less than 90 percent of saturation. At the discretion of the Department, when the Department determines that adequate information exists, the dissolved oxygen may not fall below 8.0 mg/l as a 30-day mean minimum, 6.5 mg/l as a seven-day minimum mean, and may not fall below 6.0 mg/l as an absolute minimum (Table 21);

(3)	For water bodies identified by the Department as providing cool-water aquatic life, the dissolved oxygen may not be less than 6.5 mg/l as an absolute minimum. At the discretion of the Department, when the Department determines that adequate information exists, the dissolved oxygen may not fall below 6.5 mg/l as a 30-day mean minimum, 5.0 mg/l as a seven-day minimum mean, and may not fall below 4.0 mg/l as an absolute minimum (Table 21);

(4)	For water bodies identified by the Department as providing warm-water aquatic life, the dissolved oxygen may not be less than 5.5 mg/l as an absolute minimum. At the discretion of the Department, when the Department determines that adequate information exists, the dissolved oxygen may not fall below 5.5 mg/l as a 30-day mean minimum, and may not fall below 4.0 mg/l as an absolute minimum (Table 21);

(5)	For estuarine water, the dissolved oxygen concentrations may not be less than 6.5 mg/l (for coastal water bodies);

(6)	For ocean waters, no measurable reduction in dissolved oxygen concentration may be allowed.

OAR 340-041-0006

Definitions

(15) "Daily Mean" for dissolved oxygen means the numeric average of an adequate number of data to describe the variation in dissolved oxygen concentration throughout a day, including daily maximums and minimums. For calculating the mean, concentrations in excess of 100 percent of saturation are valued at the saturation concentration.

(22) “Estuarine Waters” means all mixed fresh and oceanic waters in estuaries or bays from the point of oceanic water intrusion inland to a line connecting the outermost points of the headlands or protective jetties.

(27) "Intergravel Dissolved Oxygen" (IGDO) means the concentration of oxygen measured in the water within the stream bed gravels. Measurements should be taken within a limited time period before emergence of fry.

(34) “Marine Waters” means all oceanic, offshore waters outside of estuaries or bays and within the territorial limits of the State of Oregon.

(38) "Minimum" (Min) for dissolved oxygen means the minimum recorded concentration including seasonal and diurnal minimums.

(39) "Monthly (30-D) Mean Minimum" for dissolved oxygen means the minimum of the 30 consecutive-day floating averages of the calculated daily mean dissolved oxygen concentration.

(59) "Spatial Median" means the value that falls in the middle of a data set of multiple intergravel dissolved oxygen (IGDO) measurements taken within a spawning area. Half the samples should be greater than and half the samples should be less than the spatial median.

(73) "Weekly (7-D) Mean Minimum" for dissolved oxygen means the minimum of the seven consecutive-day floating average of the calculated daily mean dissolved oxygen concentration.

(74) "Weekly (7-Mi) Minimum Mean" for dissolved oxygen means the minimum of the seven consecutive-day floating average of the daily minimum concentration. For application of the criteria, this value is the reference for diurnal minimums.

[3.4.4]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68706


#### Assessment Protocol

The application of the various dissolved oxygen criteria is based on designated fish use as described in OAR 340-041-016 and Table 21. The time periods for assessing compliance with the dissolved oxygen standards are defined as the following:

* __Spawning Time-Period__: The spawning criteria shall be applied for places and times indicated, in the tables and figures referenced in OAR-340-041-0016 (1), as having active salmon and steelhead spawning, or any additional assumed spawning by resident trout species. Listed status of waterbodies in violation of the spawning criteria is in effect only during the applicable spawning date range for the waterbody.
* __Year-round__: The year-round dissolved oxygen criteria apply year round. For some locations, a more stringent spawning criteria may apply in addition to the year round criterion for part of the year. Listed status of waterbodies in violation of the year-round criteria are in effect year-round.

If the dissolved oxygen concentration exceeded the water quality criterion, but met the criteria for percent saturation at the same time, it was considered to be attaining the dissolved oxygen criterion. Direct field instrument measurements of percent saturation are preferred and shall be used if available. However, if corresponding percent saturation data is unavailable, and corresponding water temperature data is available, the value can be calculated using `r tbls(name = "eqns-DO-Theo", display="cite")` and `r tbls(name = "eqns-DO-PS", display="cite")`. When the dissolved oxygen saturation is measured in excess of 100 percent, the saturation value used shall be limited to 100 percent for the calculation of metrics. 

`r eqns(name = "eqns-DO-Theo",caption = "")`
$$DO_{Theo} = e ^{[-139.34411+\frac{1.575701\times 10^5}{T}-\frac{6.642308\times 10^7}{T^2}+\frac{1.23800\times 10^{10}}{T^3}-\frac{8.621949\times 10^{11}}{T^4}]} \times (1-(0.0001148 \times Site_{elvm}))$$
Where:

$DO_{Theo}$ = Theoretical Dissolved Oxygen in mg/L.

$e$ = a constant, the base of the natural logarithm ($\approx 2.71828$).

$T$ = Temperature in Kelvin.

$Site_{elvm}$ = Site elevation in meters (recorded field value or derived from a Digital Elevation Model).

`r eqns(name = "eqns-DO-PS",caption = "Percent Dissolved Oxygen Saturation")`

$$ PS = 100\times \frac{DO_{Meas}}{DO_{Theo}} $$
Where:

$PS$ = Percent saturation dissolved oxygen.

$DO_{Meas}$ = Measured Dissolved Oxygen in mg/L.

$DO_{Theo}$ = Theoretical Dissolved Oxygen in mg/L from `r tbls(name = "eqns-DO-Theo", display="cite")`.

### pH

#### Water Quality Criteria

Results for pH from both grab and continuous sample data were compared to the applicable water quality criterion as found in [OAR 340-041-0021][3.4.5].

OAR 340-041-0021

pH

(1)	Unless otherwise specified in OAR 340-041-0101 through 340-041-0350, pH values (Hydrogen ion concentrations) may not fall outside the following ranges:

|   (a)	Marine waters: 7.0-8.5;

|   (b)	Estuarine and fresh waters: See basin specific criteria (OAR 340-041-0101 through 340-041-0350).

(2)	Waters impounded by dams existing on January 1, 1996, which have pHs that exceed the criteria are not in violation of the standard, if the Department determines that the exceedance would not occur without the impoundment and that all practicable measures have been taken to bring the pH in the impounded waters into compliance with the criteria.

[3.4.5]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68713

OAR 340-041-0101 through 340-041-0350

Basin-Specific Criteria

```{r tbl-ph}

tbl.ph<- data.frame(basin=c("replace with pH table"),
                           OAR=c("replace with pH table"),
                           Water=c("replace with pH table"),
                           criteria=c("replace with pH table"))

knitr::kable(tbl.ph, 
             padding = 0, digits = 1, format = table_format,
             row.names = FALSE,
             caption = tbls(name = "tbl.ph", 
                            caption = "Summary of pH Basin-Specific Criteria."))

```

### Temperature

#### Water Quality Criteria

Results for continuous temperature data were compared against the applicable temperature criteria found in [OAR 340-041-0028][3.4.6]. The applicable temperature criteria is based on the seven day average daily maximum (7DADM) stream temperature metric. In order to ensure there was sufficient continuous data to calculate 7DADM, at least one observation per hour from noon to midnight must have been recorded. In addition, each month can have no more than one day of missing observations to ensure that no more than 10% of the 7DADM results in that month were missing.

[3.4.6]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=244176

OAR 340-041-0028

Temperature

[…]

(4)	Biologically Based Numeric Criteria. Unless superseded by the natural conditions criteria described in section (8) of this rule, or by subsequently adopted site-specific criteria approved by EPA, the temperature criteria for State waters supporting salmonid fishes are as follows:

|   (a)	The seven-day-average maximum temperature of a stream identified as having salmon and steelhead spawning use on subbasin maps and tables set out in OAR 340-041-0101 to 340-041-0340: Tables 101B, and 121B, and Figures 130B, 151B, 160B, 170B, 220B, 230B, 271B, 286B, 300B, 310B, 320B, and 340B, may not exceed 13.0 degrees Celsius (55.4 degrees Fahrenheit) at the times indicated on these maps and tables;

|   (b)	The seven-day-average maximum temperature of a stream identified as having core cold water habitat use on subbasin maps set out in OAR 340-041-101 to 340-041-340: Figures 130A, 151A, 160A, 170A, 220A, 230A, 271A, 286A, 300A, 310A, 320A, and 340A, may not exceed 16.0 degrees Celsius (60.8 degrees Fahrenheit);

|   (c)	The seven-day-average maximum temperature of a stream identified as having salmon and trout rearing and migration use on subbasin maps set out at OAR 340-041-0101 to 340-041-0340: Figures 130A, 151A, 160A, 170A, 220A, 230A, 271A, 286A, 300A, 310A, 320A, and 340A, may not exceed 18.0 degrees Celsius (64.4 degrees Fahrenheit);

|   (d)	The seven-day-average maximum temperature of a stream identified as having a migration corridor use on subbasin maps and tables OAR 340-041-0101 to 340-041-0340: Tables 101B, and 121B, and Figures 151A, 170A, and 340A, may not exceed 20.0 degrees Celsius (68.0 degrees Fahrenheit). In addition, these water bodies must have coldwater refugia that are sufficiently distributed so as to allow salmon and steelhead migration without significant adverse effects from higher water temperatures elsewhere in the water body. Finally, the seasonal thermal pattern in Columbia and Snake Rivers must reflect the natural seasonal thermal pattern;
|   (e)	The seven-day-average maximum temperature of a stream identified as having Lahontan cutthroat trout or redband trout use on subbasin maps and tables set out in OAR 340-041-0101 to 340-041-0340: Tables 120B, 140B, 190B, and 250B, and Figures 180A, 201A, and 260A may not exceed 20.0 degrees Celsius (68.0 degrees Fahrenheit);

|   (f)	The seven-day-average maximum temperature of a stream identified as having bull trout spawning and juvenile rearing use on subbasin maps set out at OAR 340-041-0101 to 340-041-0340: Figures 130B, 151B, 160B, 170B, 180A, 201A, 260A, 310B, and 340B, may not exceed 12.0 degrees Celsius (53.6 degrees Fahrenheit). From August 15 through May 15, in bull trout spawning waters below Clear Creek and Mehlhorn reservoirs on Upper Clear Creek (Pine Subbasin), below Laurance Lake on the Middle Fork Hood River, and below Carmen reservoir on the Upper McKenzie River, there may be no more than a 0.3 degrees Celsius (0.5 Fahrenheit) increase between the water temperature immediately upstream of the reservoir and the water temperature immediately downstream of the spillway when the ambient seven-day-average maximum stream temperature is 9.0 degrees Celsius (48 degrees Fahrenheit) or greater, and no more than a 1.0 degree Celsius (1.8 degrees Fahrenheit) increase when the seven-day-average stream temperature is less than 9 degrees Celsius.

[…]

(6)	Natural Lakes. Natural lakes may not be warmed by more than 0.3 degrees Celsius (0.5 degrees Fahrenheit) above the natural condition unless a greater increase would not reasonably be expected to adversely affect fish or other aquatic life. Absent a discharge or human modification that would reasonably be expected to increase temperature, DEQ will presume that the ambient temperature of a natural lake is the same as its natural thermal condition.

(7)	Oceans and Bays. Except for the Columbia River above river mile 7, ocean and bay waters may not be warmed by more than 0.3 degrees Celsius (0.5 degrees Fahrenheit) above the natural condition unless a greater increase would not reasonably be expected to adversely affect fish or other aquatic life. Absent a discharge or human modification that would reasonably be expected to increase temperature, DEQ will presume that the ambient temperature of the ocean or bay is the same as its natural thermal condition.

[…]

(9)	Cool Water Species.

|   (a)	No increase in temperature is allowed that would reasonably be expected to impair cool water species. Waters of the State that support cool water species are identified on subbasin tables and figures set out in OAR 340-041-0101 to 340-041-0340; Tables 140B, 190B and 250B, and Figures 180A, 201A and 340A

|   (b)	See OAR 340-041-0185 for a basin-specific criterion for the Klamath River.

(10) Borax Lake Chub. State waters in the Malheur Lake Basin supporting the Borax Lake chub may not be cooled more than 0.3 degrees Celsius (0.5 degrees Fahrenheit) below the natural condition.

[…]

(12) Implementation of the Temperature Criteria

|   (c)	Air Temperature Exclusion. A water body that only exceeds the criteria set out in this rule when the exceedance is attributed to daily maximum air temperatures that exceed the 90th percentile value of annual maximum seven-day average maximum air temperatures calculated using at least 10 years of air temperature data, will not be listed on the section 303(d) list of impaired waters and sources will not be considered in violation of this rule.

|   (d)	Low Flow Conditions. An exceedance of the biologically-based numeric criteria in section (4) of this rule… will not be considered a permit violation during stream flows that are less than the 7Q10 low flow condition for that water body.

OAR 340-041-0002

Definitions

(57) "Seven-Day Average Maximum Temperature" means a calculation of the average of the daily maximum temperatures from seven consecutive days made on a rolling basis.


#### Assessment Protocol

The applicable temperature criteria in `r tbls(name="tbl.temp.criteria", display="cite")` is based on the seven day average daily maximum (7DADM) stream temperature metric. In order to ensure there was sufficient continuous data to calculate 7DADM, at least one observation per hour from noon to midnight must have been recorded. In addition, each month can have no more than one day of missing observations to ensure that no more than 10% of the 7DADM results in that month were missing.

The seven-day average daily maximum stream temperature (`r tbls(name="eqns-temp-7DADM", display="cite")`) is an average of the daily maximum water temperatures for seven consecutive days. The average daily maximum temperature value for each seven-day period is assigned to the last (7th) calendar day of each period. The 7DADM is repeated for each consecutive 7-day period on a moving or rolling basis. For example, the 7DADM for August 10 is calculated from Tmax for August 4 to August 10; the 7DADM for August 11 is calculated from August 5 to 11, etc.

`r eqns(name = "eqns-temp-7DADM", caption = "")`

$$7DADM = \frac{1}{7}\sum_{i=1}^7T_{max-i} $$
Where:

$7DADM$ = the seven-day average daily maximum stream temperature.

$i$ = day in the sequence.

$T_{max}$ = maximum temperature of day $i$.

When spawning criteria apply, the first 7-day averaging period begins on the date the spawning period begins. The first 7DADM value will be assigned to the 7th calendar day following the start date of the spawning period. Therefore, the 7th calendar day of the spawning period is the first day that the 7DADM is required to meet the spawning criteria.

```{r tbl-temp}

tbl.temp.criteria <- data.frame(du=c("Salmon & trout rearing & migration", 
                                     "Core cold water habitat",
                                     "Migration corridor (salmon & steelhead)",
                                     "Lahontan cutthroat or redband trout",
                                     "Bull trout spawning & juvenile rearing",
                                     "Salmon & steelhead spawning"),
                                crit=c(18.0, 16.0, 20.0, 20.0, 12.0, 13.0))

colnames(tbl.temp.criteria) <- c("Designated Fish Use", "Temperature Criterion, deg-C")

knitr::kable(tbl.temp.criteria, 
             padding = 0, digits = 1, format = table_format,
             row.names = FALSE,
             caption = tbls(name = "tbl.temp.criteria", 
                            caption = "Numeric Temperature Criteria."))


```

##### Designated Fish Uses

The year-round fish uses designated for protection of fish and aquatic life are indicated in in OAR 340-041-0101 to 340-041-0340: Figures 130A, 151A, 160A, 170A, 180A, 201A, 220A, 230A, 260A, 271A, 286A, 300A, 310A, 320A, and 340A; Tables 101B, 120B, 121B, 130B 140B,151B, 160B, 170B, 180A, 190B, 201A, 250B, 260A, 310B, and 340B. For convenience, the information from the fish use figures and tables are also reproduced on the DEQ water quality standards maps web tool.

##### Designated Spawning Time Periods

In streams designated as salmon and steelhead spawning areas, the salmon & steelhead spawning criterion (13°C) shall be applied ONLY during the time periods indicated in tables and figures referenced in OAR 340-041-0101 to 340-041-0340: Tables 101B, and 121B, and Figures 130B, 151B, 160B, 170B, 220B, 230B, 271B, 286B, 300B, 310B, 320B, and 340B. Outside of these designated spawning time periods, the year-round criteria shall apply. For convenience, the information from the spawning use tables and figures are also reproduced on the DEQ water quality standards maps web tool (under development).

##### Application of the Cool Water Species narrative criterion for temperature in 340-041-0028 (9)(b) in the Upper Klamath and Lost Subbasins

To ensure the protection of Lost River and Shortnose Suckers in the Klamath River, Link River, and Lost River, the Upper Klamath and Lost Subbasins Temperature TMDL (DEQ 2019) developed TMDL targets to implemented the Cool Water Species narrative criterion. If daily maximum results exceed 28°C in these reaches DEQ will determine that the cool water species narrative criterion is not being attained.

##### Applicability

For tributary waters that are not identified on the “Fish Use Designations” maps referenced in section (4) of the rule, the applicable criteria for these waters are the same criteria as is applicable to the nearest downstream water body depicted on the applicable map. This does not apply to the "Salmon and Steelhead Spawning Use Designations" maps.

Oregon does not have explicit water quality standards for total phosphorus (TP) or total suspended solids (TSS) however sometimes these parameters are pollutants that contribute to an impairment of water quality standards. Often the impairment is based on standards established for dissolved oxygen, pH, sediment, or other chemicals. 

In this report, we evaluated status for total phosphorus or total suspended solids in the Willamette Basin where a Total Maximum Daily Load has been established and identifies total phosphorus or total suspended solids as a pollutant with specific concentration targets. Other TMDLs established in other parts of the state with total phosphorus or total suspended solids concentration targets were not evaluated.

### Total Phosphorus

Oregon does not have explicit water quality standards for total phosphorus (TP) however total phosphorus can be a pollutant that contributes to an impairment of water quality standards. Often the impairment is for standards established for dissolved oxygen, pH, or algae. 

In this report, we evaluated status for total phosphorus in the Willamette Basin where a Total Maximum Daily Load has been established and identifies total phosphorus as a pollutant with specific concentration targets. Other TMDLs established in other parts of the state with total phosphorus concentration targets were not evaluated. `r tbls(name="tp.tmdls", display="cite")` summarizes the TMDLs evaluated in this report.

```{r tbl-TP-tmdls}

tbl.tp.tmdls <- data.frame(tmdl=c("Tualatin Subbasin TMDL and WQMP",
                                  "Columbia Slough TMDL",
                                  "TMDLs for the Yamhill River"),
                           year=c(2012,1998,1992),
                           impairments=c("pH and Chlorophyll a",
                                         "Algae and pH",
                                         "Algae and pH "),
                           geoarea=c("Tualatin Subbasin (HUC 17090010), Tributaries to Oswego Lake (HUC 170900120104)",
                                     "Columbia Slough, Fairview Creek (HUC 170900120201)",
                                     "Yamhill River (HUC 17090008)"))


colnames(tbl.tp.tmdls) <- c("TMDL Document Name", "Year Approved", "Impairments", "Applicable Geographic Area")

knitr::kable(tbl.tp.tmdls,
             padding = 0, digits = 1, format = table_format,
             row.names = FALSE,
             caption = tbls(name = "tp.tmdls", 
                            caption = "Summary of TMDLs with total phosphorus targets that were evaluated in this report."))

```

The total phosphorus interim target established in the Columbia Slough TMDL (DEQ 1998) for Columbia Slough and Fairview Creek is 0.1 mg/L.

The Yamhill River TMDL (DEQ 1992) target for total phosphorus is defined as 0.07 mg/L.

The Tualatin Subbasin TMDL (DEQ 2012) established summer median total phosphorus targets for the Tualatin River and its tributaries. Summer is defined as May 1 – October 3. Total phosphorus targets are also defined for tributaries to Oswego Lake. `r tbls(name="tualatin.targets", display="cite")` and `r tbls(name="oswego.targets",display="cite")` describe these targets.

```{r tbl-tualatin-targets}

tbl.tualatin <- data.frame(Segment=c("Mainstem Tualatin River @ Stafford Rd. (RM 5.5)",
                                     "Mainstem Tualatin River @ Hwy 99W (RM 11.6)",
                                     "Mainstem Tualatin River @ Elsner (RM 16.2)",
                                     "Mainstem Tualatin River @ Farmington (RM 33.3)",
                                     "Mainstem Tualatin River @ Rood Rd. (RM 38.4)",
                                     "All Tributaries to the Mainstem Tualatin above Dairy Creek (Unless otherwise specified below)",
                                     "All Tributaries to the Mainstem Tualatin below Dairy Creek (Unless otherwise specified below)",
                                     "Mainstem Tualatin River @ Golf Course Rd. (RM 51.5)",
                                     "Bronson Creek @ Mouth (205th)",
                                     "Burris Cr./ Baker Cr./ McFee Cr./ Christensen Cr./ (all @ Month)",
                                     "Cedar Cr./ Chicken Cr/ /Rock Cr. (South)/ Nyberg Cr./ Hedges Cr./ Saum Cr. (all @ Mouth)",
                                     "Dairy Creek @ Mouth",
                                     "Fanno Creek @ Mouth",
                                     "Gales Creek @ Mouth",
                                     "Rock Creek @ Mouth"), 
                           target=c(0.10,
                                    0.11,
                                    0.11,
                                    0.10,
                                    0.09,
                                    0.04,
                                    0.14,
                                    0.04,
                                    0.13,
                                    0.12,
                                    0.14,
                                    0.09,
                                    0.13,
                                    0.04,
                                    0.19))

colnames(tbl.tualatin) <- c("Stream Segment","Total Phosphorus Concentrations (Summer Median – mg/L)")

knitr::kable(tbl.tualatin, 
             padding = 0, digits = 2, format = table_format,
             row.names = FALSE,
             caption = tbls(name = "tualatin.targets", 
                            caption = "Total phosphorus targets in Tualatin River and tributaries."))

```

```{r tbl-oswego-targets}

tbl.oswego <- data.frame(event=c("Base Flow","Storm","Base Flow"), 
                         period=c("May 1 through October 31 (Summer)",
                                  "November 1 through April 30 (Winter)",
                                  "November 1 through April 30 (Winter)"),
                         target=c(0.11,0.19,0.08))

colnames(tbl.oswego) <- c("Flow Type", "Period", "Maximum Total Phosphorus Concentrations (mg/L)")

knitr::kable(tbl.oswego, 
             padding = 0, digits = 2, format = table_format,
             row.names = FALSE,
             caption = tbls(name = "oswego.targets", 
                            caption = "Total phosphorus targets in Oswego Lake and tributaries."))

```

### Total Suspended Solids

Oregon does not have explicit water quality standards for total suspended solids (TSS) however TSS has been identified as a pollutant that contributes to impairment of water quality standards. Often the impairment is based on standards established for sediment, metals, or other toxic chemicals. 

In this report, we evaluated status for total suspended solids in the Willamette Basin where a Total Maximum Daily Load has been established and identifies total suspended solids as a pollutant with specific concentration targets. Other TMDLs established in other parts of the state with total suspended solids concentration targets were not evaluated. `r tbls(name="tss.tmdls", display="cite")` summarizes the TMDLs evaluated in this report.

```{r tbl-TSS-tmdls}

tbl.tss.tmdls <- data.frame(tmdl=c("Molalla-Pudding Subbasin TMDL and WQMP",
                                  "Willamette Basin TMDL"),
                           year=c(2008,2006),
                           impairments=c("Iron and dichlorodiphenyltrichloroethane (DDT)",
                                         "dichlorodiphenyltrichloroethane (DDT)"),
                           geoarea=c("Pudding River, Little Pudding River, and Zollner Creek (HUC 17090009)",
                                     "Johnson Creek Watershed (HUC 1709001201)"))


colnames(tbl.tss.tmdls) <- c("TMDL Document Name", "Year Approved", "Impairments", "Applicable Geographic Area")

knitr::kable(tbl.tss.tmdls,
             padding = 0, digits = 1, format = table_format,
             row.names = FALSE,
             caption = tbls(name = "tss.tmdls", 
                            caption = "Summary of TMDLs with total suspends solids targets that were evaluated in this report."))

```


The Molalla-Pudding Subbasin TMDL established instream TSS concentration targets of 15 mg/L and 6 mg/L for the Pudding River to attain the DDT and Iron criteria respectively. On Zollner Creek the targets for TSS are 15 mg/L and 3 mg/L to attain the DDT and Iron criteria respectively. On the Little Pudding River the TSS target is 7 mg/L to attain the DDT criterion.

The Willamette Basin TMDL (DEQ 2006) TSS was identified as a surrogate measure for DDT in the Johnson Creek Watershed. The TMDL established an instream TSS concentration of 15 mg/L in order to achieve a DDT reduction of 94%.

## Water Quality Trend Evaluation

### Assessment Units

Water quality trends were evaluated at monitoring stations only. 

### Trend Result Categories and Definitions

The water quality trends at stations are reported using the following categories:

* __Improving__: When the result demonstrates a statistically significant trend in advancement of water quality conditions
* __Degrading__: When the result shows a statistically significant trend in deterioration of water quality conditions
* __Steady__: When the result has a statistically significant slope that equals to zero, which indications neither improving or degrading in water quality conditions
* __No Significant Trend__: When there is no consistent overall trend
* __Insufficient Data__: When there are results available but the results do not meet QA/QC objectives including minimum Data Quality Levels (DQLs); or the results do not meet minimum requirements to evaluate attainment of the water quality criteria or TMDL target.

### Parameters Evaluated

Trends were calculated for dissolved oxygen, bacteria, pH, temperature, total phosphorus, and total suspended solids. 

### Statistical Method

A Seasonal Kendall test (Hirsch et al. 1982, Hirsch and Slack 1984, and Helsel and Hirsch 2002) was used for the trend evaluation. A Seasonal Kendall test is a nonparametric method used to test for a monotonic trend and can account for the influence of seasonal fluctuations by calculating a Mann-Kendall test (Mann 1945) on each defined season separately. A season can be any time period. In this analysis each calendar month defined a season. Multiple observations within any given month were collapsed into a single value using the median. There are twelve seasons in a year. After computing the Mann-Kendall for each season, the seasonal statics are summed, and the variance and Z statistic are computed.

For each parameter at each station where there were sufficient data to evaluate trend, the null hypothesis is that there is no monotonic trend over time. The alternative hypothesis is that for one or more seasons, there is an upward, downward, or steady monotonic trend over time. The null hypothesis is rejected (and we determine there is a trend) if the Z statistic (two-tailed p value) <= 0.20.

A trend assessment using Seasonal Kendall cannot be made at a monitoring station unless the results there have an underlying regularity and there is sufficient data over time. We did not attempt to calculate trend unless there were water quality results in the same month for at least eight different years over the entire twenty year analysis period. We define “results” as a water quality observation or a calculated observation in the statistical units of the water quality criteria (i.e. geomean or 7-day average daily maximum). If there were insufficient data, “Insufficient Data” is assigned as the result. At stations with sufficient data, a significant positive, negative, or steady trend was determined across all seasons and years when the significance of the trend slopes had a two-tailed p <= 0.20. “Improving” or “Degrading” are assigned to a positive or negative slopes depending on the water quality standards and if an increasing or decreasing values were an improvement or derogation of water quality. For example, a positive result (increasing value with time) is considered an improving trend for dissolved oxygen but degrading trend for temperature. A steady trend had a slope equal to zero. “No significant Trend” is assigned when the null hypothesis is not rejected and indicates there is no consistent overall trends during the evaluation period.

## Watershed Restoration or Protection Actions

To summarize actions taken to restore or protect watersheds and water quality, we summarized on-the-ground treatments implemented and reported to OWEB’s Oregon Watershed Restoration Inventory (OWRI). OWRI is a repository for a significant number of actions implemented in Oregon but it does not capture all restoration or protection actions. In particular projects funded by the United States Farm Bill and many USFS and BLM projects are not included. Typically treatments reported to OWRI were implemented as part of an OWEB grant funded project. DEQ also requires federal 319 grant recipients to report outputs to OWRI. There are over 130 unique treatments identified in OWRI. The various treatments can be grouped broadly into the following activity types: fish passage, fish screening, instream habitat, instream flow, riparian, road, upland, and urban.  For this report we counted any treatment towards the total if they were implemented in Oregon over the twenty year period of analysis. We subdivided the total into five shorter periods with each period being four years. Only treatments completed within the four year period counted towards the total for that period. The year the project was completed was used for multi-year projects. The totals are reported by subbasin for each activity type and treatment.

# Results

## Statewide

```{r stateIntro, include = TRUE, results = 'asis', fig.cap = cap_list, eval.after = 'fig.cap'}

au_types <- unique(state_param_sum_au$AU_Type)
n_au_ids <- length(unique(state_param_sum_au$AU_ID))
n_au_types <- length(unique(state_param_sum_au$AU_Type))
n_stations <- length(unique(state_param_sum_stn$MLocID))
parameters <- odeqstatusandtrends::AWQMS_to_standard(unique(state_param_sum_au$Char_Name))
n_params <- length(unique(state_param_sum_au$Char_Name))
list_fun <- function(x){paste(x, collapse = "s', '")}
cap_list <- list()

cat(paste0("Available data were sufficient to assess status and/or trend at ", n_stations, " stations within the state. These stations were located across ", n_au_ids, " assessment units consisting of '", list_fun(au_types[1:(n_au_types - 1)]), "s' and '", list_fun(au_types[n_au_types]), "s'. Data for ", 
           gsub("'", "", 
                paste0(paste(parameters[1:(n_params - 1)], collapse = "', '"), "' and '", paste(parameters[n_params], collapse = "', '")
                       , "'")
           ), " were available for analysis and included in this report. The following section summarizes the results of the analysis state wide.\n\n"))

```

The map in `r figs(name = "query_map", display="cite")` shows the locations of all of the stations that were queried across the state.

```{r stations_map, include=FALSE}

HUC_shp <- readOGR(dsn = "N:/Status_and_Trend_Reports/GIS", layer = 'Report_Units_HUC08', integer64="warn.loss", verbose = FALSE, stringsAsFactors = FALSE)
basin_names <- sort(unique(HUC_shp$REPORT))

stations_AWQMS <- get_stations_AWQMS(HUC_shp)
huc_names <- unique(stations_AWQMS[,c("HUC8", "HUC8_Name")]) %>% filter(HUC8_Name != "-9999")

HUC_shp <- sf::st_as_sf(HUC_shp)
HUC_shp <- st_transform(HUC_shp, 4326)

if(!file.exists(paste0(state_project_dir, "Oregon_query_stations.png"))){
  query_map <- leaflet(stations_AWQMS, options = leafletOptions(zoomControl = FALSE)) %>% addProviderTiles("Esri.NatGeoWorldMap") %>% 
    addPolygons(data = HUC_shp, fill = FALSE, opacity = 1, weight = 1.5, color = "black") %>% 
    addCircleMarkers(lng = ~Long_DD, lat = ~Lat_DD, stroke = TRUE, weight = 1, opacity = 1, fillOpacity = 1, radius = 1.5,
                     color = "black", fillColor = "green")
  
  mapview::mapshot(query_map, file = paste0(state_map_dir, "Oregon_query_stations.png"), remove_controls = c("zoomControl", "layersControl"))
}

```

`r paste0("![", figs(name = "query_map", caption = "All stations queried across the state"), "](", paste0(state_project_dir, "Oregon_query_stations.png"), ")")`

```{r stateResults, include = TRUE, results = 'asis', fig.cap = cap_list, eval.after = 'fig.cap'}

cat("### Parameter Summary Maps\n\n")
# fignum <- 1

for(i in unique(state_param_sum_stn$Char_Name)){
  if(i != "pH"){
    parameter_name <- simpleCap(i)
  } else {parameter_name <- "pH"}
  
  # cat(paste(i, "map"))
  # cat("\n\n")
  
  if(!file.exists(paste0(state_map_dir, "Oregon_", gsub(",| ", "_", i), ".png"))){
    wql_streams_i <- filter(state_wql_streams_shp, Char_Name == i)
    # wql_streams_i <- wql_streams_i[lapply(wql_streams_i$`_ogr_geometry_`, length) != 0,]
    
    map_df <- state_param_sum_stn %>% filter(Char_Name == i) %>% mutate(color = if_else(!!status_current %in% c("Unassessed", "Insufficient Data"),
                                                                                    "lightgray",
                                                                                    if_else(!!status_current == "Not Attaining",
                                                                                            "orange",
                                                                                            "green")
    ))
    
    map <- leaflet(options = leafletOptions(zoomControl = FALSE)) %>% 
      addProviderTiles("Esri.NatGeoWorldMap") %>%
      addPolylines(data = wql_streams_i,
                   opacity = 1,
                   weight = 2,
                   color = "red"
                   # ,
                   # popup = ~paste0("<b>", STREAM_NAM,
                   #                 "<br>Parameter:</b> ", Char_Name,
                   #                 "<br><b>Listing:</b> ", LISTING_ST),
                   # popup = ~paste0("<b>", STREAM_NAM,
                   #                 # "<br>Parameter:</b> ", Char_Name,
                   #                 "<br></b><br>",
                   #                 sapply(SEGMENT_ID, WQLpopupTable, param = i, USE.NAMES = FALSE)),
                   # popupOptions = popupOptions(maxWidth = 1200),
                   # highlightOptions = highlightOptions(color = "red", weight = 8, opacity = 1),
                   # label = ~STREAM_NAM,
                   # smoothFactor = 2
                   # ,
                   # group = "WQ Listed Streams"
      ) %>%
      addPolygons(data = HUC_shp, fill = FALSE, opacity = 1, weight = 1.5, color = "black") %>%
      addCircleMarkers(data = map_df, lng = ~Long_DD, lat = ~Lat_DD,
                       fillColor = ~color, stroke = TRUE, weight = 0.5,
                       opacity = 1, fillOpacity = 1, color = 'black', radius = 2.5) %>% 
      addControl(position = "bottomright", className = "legend",
               html = sprintf('<html><body><div style="opacity:0.95">
                                        <img width="150" height="140" src="data:image/png;base64,%s">
                            </div></body></html>', lgnd)) %>% 
      addControl(html = paste('<div style="opacity:0.95; background:white; padding:0px 6px; border-radius: 8px; font-size:18px"><b>', 
                              "Oregon", parameter_name, "Status</b></div>"), 
                 position = "topleft", className = "map_title")
    # %>%
    #   leafem::addLogo(img = "N:/Status_and_Trend_Reports/Figures/map_overview_legend.png", src = "local", alpha = 1, position = "bottomleft",
    #                   offset.x = 10, offset.y = 10, width = 150, height = 150)
    
    # maps[[i]] <- map
    mapview::mapshot(map, file = paste0(state_map_dir, "Oregon_", gsub(",| ", "_", i), ".png")
                     # , remove_controls = c("zoomControl", "layersControl")
                     )
  }
  
  cat(paste0("![", figs(name = paste0("state_", i, "_map"), 
                        caption = paste0("Summary map of the status of ", i, " across the state")),
             "](", state_map_dir, "Oregon_", gsub(",| ", "_", i), ".png)"), "\n")
  # cat()
  # fignum <- fignum + 1
  cat("\n\n")
}

cat("### Status\n\n")

cat(paste0(tbls("au_sum", display = 'cite')," shows the number of attaining, not attaining, and unassessed assessment units by parameter.\n\n"))

au_sum <- state_param_sum_au %>% group_by(Char_Name) %>% 
  summarise(Attaining = sum(status_2015_2018 == "Attaining"),
            'Not Attaining' = sum(status_2015_2018 == "Not Attaining"),
            Unassessed = sum(status_2015_2018 == "Unassessed")) %>% 
  mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  rename(Pollutant = Char_Name)

# cat(tbls(name = "au_sum", caption = "Summary of assessment unit status across the state."))

knitr::kable(au_sum, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "au_sum", caption = "Summary of assessment unit status across the state.")
             ) %>% table_style()

cat("\n\n")

au_sum_plot <- ggplot(reshape2::melt(au_sum, id.vars = "Pollutant", variable.name = "Status"))+
  geom_bar(aes(x = Pollutant, y = value, fill = Status), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_not_attaining, fill = "Not Attaining"), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_unassessed, fill = "Unassessed"), stat = "identity", position = "dodge")+
  xlab("Pollutant")+
  ylab("# of Assessment Units")+
  scale_fill_manual(values = c("Attaining" = "forestgreen", "Not Attaining" = "orange", "Unassessed" = "gray"))+
  theme_bw()+
  ggtitle("Assessment Unit Attainment Count", subtitle = "Summarized by Pollutant")

au_sum_plot
cap_list[[1]] <- figs(name = paste0("state_au_sum_plot"), caption = paste0("Summary plot of assessment unit status across the state by parameter."))
# cat(paste0("![", figs(name = paste0("state_au_sum_plot"), caption = paste0("Summary plot of assessment unit status across the state by parameter.")),
#            "]()"))

cat(paste0("\n\n", tbls("au_type_sum", display = 'cite')," contains a summary of the number of attaining, not attaining, and unassessed assessment units by parameter and assessment unit type.\n\n"))

au_sum_type <- state_param_sum_au %>% group_by(AU_Type, Char_Name) %>% 
  summarise(Attaining = sum(status_2015_2018 == "Attaining"),
            'Not Attaining' = sum(status_2015_2018 == "Not Attaining"),
            Unassessed = sum(status_2015_2018 == "Unassessed")) %>% 
  mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  rename("AU Type" = AU_Type, Pollutant = Char_Name)

# cat(tbls(name = "au_type_sum", caption = "Statewide status summary of assessment units by type."))

knitr::kable(au_sum_type, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "au_type_sum", caption = "Statewide status summary of assessment units by type.")
             ) %>% table_style()
             

cat("\n\n")

cat(paste0("\n\n", tbls("stn_sum", display = 'cite') ," summarizes the number of attaining, not attaining, and unassessed stations by parameter.\n\n"))

stn_sum <- state_param_sum_stn %>% group_by(Char_Name) %>% 
  summarise(Attaining = sum(status_2015_2018 == "Attaining"),
            "Not Attaining" = sum(status_2015_2018 == "Not Attaining"),
            Unassessed = sum(status_2015_2018 == "Unassessed"))%>% 
  mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  rename(Pollutant = Char_Name)

# cat(tbls(name = "stn_sum", caption = "Summary of the status of stations across the state."))

knitr::kable(stn_sum, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "stn_sum", caption = "Summary of the status of stations across the state.")
             ) %>% table_style()

cat("\n\n")

stn_sum_plot <- ggplot(reshape2::melt(stn_sum, id.vars = "Pollutant", variable.name = "Status"))+
  geom_bar(aes(x = Pollutant, y = value, fill = Status), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_not_attaining, fill = "Not Attaining"), stat = "identity", position = "dodge")+
  # geom_bar(aes(x = Char_Name, y = n_unassessed, fill = "Unassessed"), stat = "identity", position = "dodge")+
  xlab("Pollutant")+
  ylab("# of Stations")+
  scale_fill_manual(values = c("Attaining" = "forestgreen", "Not Attaining" = "orange", "Unassessed" = "gray"))+
  theme_bw()+
  ggtitle("Station Attainment Count", subtitle = "Summarized by Pollutant")

stn_sum_plot
cap_list[[2]] <- figs(name = paste0("state_stn_sum_plot"), caption = paste0("Summary plot of station status across the state by parameter."))
# cat(paste0("![", figs(name = paste0("state_stn_sum_plot"), caption = paste0("Summary plot of station status across the state by parameter.")),
#            "]()"))

# fignum <- fignum + 1

cat("\n\n")
cat("### Trend\n\n")

cat(paste0("\n\nA summary of the trends across parameters is shown in ", tbls("stn_trend_sum", display = 'cite'),". Note that trend requires significantly more data than status and may result in many stations with sufficient data for assessing status, but insufficient data for assessing trend.\n\n"))

stn_sum <- state_param_sum_stn %>% group_by(Char_Name) %>% 
  summarise(Improving = sum(trend == "Improving"),
            Degrading = sum(trend == "Degrading"),
            Steady = sum(trend == "Steady"),
            "No Significant Trend" = sum(trend == "No Significant Trend"),
            "Insufficient Data" = sum(trend == "Insufficient Data"),
  ) %>% 
  mutate(Char_Name = sapply(Char_Name, simpleCap, USE.NAMES = FALSE)) %>% 
  rename(Pollutant = Char_Name)

# cat(tbls(name = "stn_trend_sum", caption = "Statewide summary of trends at stations across the state."))

knitr::kable(stn_sum, padding = 0, digits = 1, row.names = FALSE, format = table_format,
             caption = tbls(name = "stn_trend_sum", caption = "Statewide summary of trends at stations across the state.")
             ) %>% table_style()

cat("\n\n")

# cat("## OWRI Watershed Restoration Actions")
# cat("\n\n")

# owri_basin <- owri_summary %>% group_by(ActivityType, Treatment_Unit) %>% summarise_at(colnames(owri_summary)[5:10], sum)
# action_df <- owri_basin[owri_basin$Total != 0,]
# actions <- unique(action_df$ActivityType)
# n_action <- length(actions)
# n_units <- length(unique(action_df$Treatment_Unit))
# 
# cat(paste0("According to the Oregon Watershed Restoration Inventory (OWRI), ", n_action, " types of restoration actions have been implemented across the ", basin, " basin including '", paste(actions[1:(n_action-1)], collapse = "', '"), "' and '", paste(actions[n_action], collapse = "', '"), "' activities encompassing ", n_units, " different forms of treatment units. ", tbls(paste0(basin, "_owriTab"), display = "cite"), " summarizes reported treatment outputs reported to the Oregon Watershed Restoration Inventory (owri) for numerous watershed restoration projects within the  ", basin, " basin. Basin Treatment summaries are grouped into yearly periods. The year refers to the year the project was completed."))
#   
# cat("\n\n")
# 
# colnames(owri_basin) <- sapply(gsub("_", " ", colnames(owri_basin)), simpleCap, USE.NAMES = FALSE)
# 
# cat(tbls(name = paste0(basin, "_owriTab"), 
#          caption = paste("Summary of watershed restoration actions implemented and reported to the Oregon Watershed Restoration Inventory in the ",
#                          basin, " basin. Source: OWEB OWRI ", owri_version)
# )
# )
# capnum <- tbls(paste0(basin, "_owriTab"), display = "num")
# 
# t <- knitr::kable(owri_basin, format = table_format, padding = 0, digits = 1, row.names = FALSE
# ) %>% table_style()
# 
# print(t)
# 
# cat("\n\n")

```


```{r Basins, include=FALSE}

basin_output <- NULL
# capnum <- 6

appendix_letter <- list("Black Rock Desert-Humboldt"="A",
                        "Columbia River"="B",
                        "Deschutes"="C",
                        "Goose Lake"="D",
                        "Grande Ronde"="E",
                        "John Day"="F",
                        "Klamath"="G",
                        "Malheur"="H",
                        "Mid-Coast"="I",
                        "Middle Columbia-Hood"="J",
                        "North Coast-Lower Columbia"="K",
                        "Oregon Closed Basins"="L",
                        "Owyhee"="M",
                        "Powder-Burnt"="N",
                        "Rogue"="O",
                        "Sandy"="P",
                        "Snake River"="Q",
                        "South Coast"="R",
                        "Umatilla-Walla Walla-Willow"="S",
                        "Umpqua"="T",
                        "Willamette"="U")
  
for(i in basin_names){
 
   name <- i
   a.letter <- appendix_letter[[name]]
  
   basin_output <- c(basin_output, knitr::knit_child(input = "state_basin_summary.Rmd", envir = globalenv()))
}

```

`r paste(basin_output, collapse = "\n")`


# Citations

Helsel, D.R. and R. M. Hirsch, 2002. Statistical Methods in Water Resources Techniques of Water Resources Investigations, Book 4, chapter A3. U.S. Geological Survey. 522 pages.

Hirsch, R.M. and J.R. Slack. 1984. A nonparametric trend test for seasonal data with serial dependence. *Water Resources Research* 20(6):727-732.

Hirsch, R.M., J.R. Slack and R.A. Smith. 1982. Techniques of trend analysis for monthly water quality data. *Water Resources Research* 18(1):107-121.

Mann, H. B., 1945, Nonparametric test against trend: *Econometrica* 13, 245-259.

Oregon Department of Environmental Quality [DEQ]. 1992. TMDLs for the Yamhill River. https://www.oregon.gov/deq/FilterDocs/YamhillTMDL1992.pdf

Oregon Department of Environmental Quality [DEQ]. 1998. Columbia Slough TMDL. https://www.oregon.gov/deq/FilterDocs/columbiasloughtmdl.pdf

Oregon Department of Environmental Quality [DEQ]. 2006. Willamette Basin TMDL. https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Willamette-Basin.aspx

Oregon Department of Environmental Quality [DEQ]. 2008. Molalla-Pudding Subbasin TMDL and WQMP. https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Willamette-Basin.aspx

Oregon Department of Environmental Quality [DEQ]. 2012. Tualatin Subbasin TMDL and WQMP. https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Willamette-Basin.aspx

Oregon Department of Environmental Quality [DEQ]. 2013. Data validation criteria for water quality parameters measured in the field. DEQ04-LAB-0003-QAG Version5.0. http://www.oregon.gov/deq/FilterDocs/DataQualMatrix.pdf

Oregon Department of Environmental Quality [DEQ]. 2019. Upper Klamath and Lost Subbasins Temperature TMDL and WQMP. https://www.oregon.gov/deq/wq/tmdls/Pages/TMDLs-Klamath-Basin.aspx#2019tmdl



